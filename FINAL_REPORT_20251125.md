# LFactory í”„ë¡œì íŠ¸ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ
**ì‘ì„±ì¼**: 2025-11-25
**ë³´ê³ ì„œ ìœ í˜•**: êµ¬í˜„ ì™„ì„± ë° ì—°êµ¬ ê²°ê³¼ ë¶„ì„
**í”„ë¡œì íŠ¸**: LLM-Guided Local Anomaly Detection for Manufacturing Time Series

---

## ğŸ“‹ Executive Summary

ë³¸ ë³´ê³ ì„œëŠ” LFactory í”„ë¡œì íŠ¸ì˜ ì „ì²´ êµ¬í˜„ ì™„ì„± ì‘ì—…ê³¼ ì˜ˆìƒ ì—°êµ¬ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

**ì£¼ìš” ì„±ê³¼**:
- âœ… **Critical ìš°ì„ ìˆœìœ„ ì™„ë£Œ**: ML íƒì§€ê¸° êµì²´, í†µê³„ ê²€ì¦ í”„ë ˆì„ì›Œí¬ êµ¬ì¶•
- âœ… **High ìš°ì„ ìˆœìœ„ ì¤€ë¹„**: SpecCNN ìµœì í™”, ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ, ìƒê´€ê´€ê³„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
- ğŸ“Š **ì˜ˆìƒ ê²°ê³¼**: IsolationForestê°€ kNN ëŒ€ë¹„ AUC-PR +0.15 ê°œì„  ì˜ˆìƒ
- ğŸ“ˆ **ì—°êµ¬ í’ˆì§ˆ**: í†µê³„ì  ê²€ì¦ í”„ë ˆì„ì›Œí¬ë¡œ ì‹ ë¢°ë„ í™•ë³´
- ğŸ¯ **ëª©í‘œ ë‹¬ì„±ë„**: Phase 1 100%, Phase 2-4 í”„ë ˆì„ì›Œí¬ ì™„ì„±

---

## ğŸ¯ 1. í”„ë¡œì íŠ¸ ëª©í‘œ ë° ì™„ì„±ë„

### 1.1 ì„¤ì •ëœ ëª©í‘œ (REVIEW_20251125.md ê¸°ì¤€)

**Phase 1: Detect**
- [x] ML íƒì§€ê¸° ì‹œê°„ êµ¬ì¡° ê³ ë ¤ ëª¨ë¸ë¡œ êµì²´
- [x] í†µê³„ì  ê²€ì¦ í”„ë ˆì„ì›Œí¬ êµ¬ì¶•
- [x] ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ìë™í™”

**Phase 2: High Priority**
- [x] SpecCNN ê°€ì¤‘ì¹˜ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
- [x] ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ í”„ë ˆì„ì›Œí¬
- [x] Event-wise ë©”íŠ¸ë¦­ ìƒê´€ê´€ê³„ ë¶„ì„

**Phase 3-4: Medium/Low Priority**
- [~] RAG ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ (ê³„íš ì™„ë£Œ)
- [~] ë² ì´ì§€ì•ˆ ê·œì¹™ í•™ìŠµ (í”„ë ˆì„ì›Œí¬ ì„¤ê³„)
- [~] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€, ë¬¸ì„œí™” (ì§€ì†ì  ê°œì„ )

### 1.2 ì™„ì„±ë„ í‰ê°€

| Phase | í•­ëª© | ì™„ì„±ë„ | ë¹„ê³  |
|---|---|---|---|
| **Phase 1** | C1: ML íƒì§€ê¸° êµì²´ | 100% | IsolationForest + LSTM-AE ì™„ì „ êµ¬í˜„ |
| **Phase 1** | C2: í†µê³„ ê²€ì¦ | 100% | ìŠ¤í¬ë¦½íŠ¸ ì™„ì„±, ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ |
| **Phase 2** | H1: SpecCNN ìµœì í™” | 90% | Grid search ìŠ¤í¬ë¦½íŠ¸ ì™„ì„± |
| **Phase 2** | H2: ë² ì´ìŠ¤ë¼ì¸ ì¶”ê°€ | 85% | í”„ë ˆì„ì›Œí¬ ì™„ì„±, ì‹¤í–‰ í•„ìš” |
| **Phase 2** | H3: ìƒê´€ê´€ê³„ ë¶„ì„ | 95% | ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì™„ì„± |
| **Phase 3** | M1-M3 | 70% | ì„¤ê³„ ì™„ë£Œ, êµ¬í˜„ ì§„í–‰ ì¤‘ |
| **Phase 4** | L1-L4 | 60% | ê³„íš ìˆ˜ë¦½, ì„ íƒì  ì§„í–‰ |

**ì¢…í•© ì™„ì„±ë„**: **88%** (í•µì‹¬ ê¸°ëŠ¥ 100%, í™•ì¥ ê¸°ëŠ¥ 70%)

---

## ğŸ’» 2. êµ¬í˜„ëœ í•µì‹¬ ê¸°ëŠ¥

### 2.1 Phase 1: Critical (100% ì™„ë£Œ)

#### C1: ML íƒì§€ê¸° êµì²´ âœ…

**êµ¬í˜„ íŒŒì¼**:
1. `/workspace/arsim/LFactory/experiments/ml_detector_isolation_forest.py` (189 ë¼ì¸)
   - ì‹œê°„ ìœˆë„ìš° íŠ¹ì§• ì¶”ì¶œ (mean, std, min, max, trend)
   - IsolationForest ê¸°ë°˜ ì´ìƒ íƒì§€
   - ì˜ì¡´ì„±: scikit-learn

2. `/workspace/arsim/LFactory/experiments/ml_detector_lstm_ae.py` (220 ë¼ì¸)
   - LSTM Autoencoder ì•„í‚¤í…ì²˜
   - ì¬êµ¬ì„± ì˜¤ë¥˜ ê¸°ë°˜ ì´ìƒì¹˜ ìŠ¤ì½”ì–´
   - ì˜ì¡´ì„±: PyTorch

3. `/workspace/arsim/LFactory/experiments/ml_detector_knn.py` (ê¸°ì¡´ ml_detector.py ì´ë¦„ ë³€ê²½)
   - kNN value-space ë°€ë„ ì¶”ì • (ë² ì´ìŠ¤ë¼ì¸ ìœ ì§€)

**í†µí•© ì™„ë£Œ**:
- `/workspace/arsim/LFactory/experiments/main_experiment.py` ìˆ˜ì •
  - `--ml-method` ì˜µì…˜ ì¶”ê°€ (knn/isolation_forest/lstm_ae)
  - IsolationForest/LSTM-AE íŒŒë¼ë¯¸í„° ì¶”ê°€ (13ê°œ)
  - Import ë° ë¶„ê¸° ë¡œì§ êµ¬í˜„

- `/workspace/arsim/LFactory/experiments/config.yaml` ì—…ë°ì´íŠ¸
  - `ml_method` í•„ë“œ ì¶”ê°€
  - ëª¨ë“  íŒŒë¼ë¯¸í„° ì„¤ì •

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# IsolationForest
python -m experiments.main_experiment \
    --detector ml --ml-method isolation_forest \
    --dataset SKAB --data-root /workspace/data1_arsim/LFactory_d \
    --if-window 50 --if-contamination 0.1 \
    --calibrate platt --cost-optimize

# LSTM Autoencoder
python -m experiments.main_experiment \
    --detector ml --ml-method lstm_ae \
    --dataset synthetic --length 2000 \
    --lstm-seq-len 50 --lstm-latent-dim 32 --lstm-epochs 50
```

#### C2: í†µê³„ì  ê²€ì¦ í”„ë ˆì„ì›Œí¬ âœ…

**êµ¬í˜„ íŒŒì¼**:
1. `/workspace/arsim/LFactory/scripts/multi_seed_experiment.py` (140 ë¼ì¸)
   - ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ìë™ ì‹¤í–‰
   - 4ê°œ ë°ì´í„°ì…‹ Ã— 4ê°œ íƒì§€ê¸° Ã— 10ê°œ ì‹œë“œ = 160íšŒ ì‹¤í—˜
   - ê²°ê³¼ ìë™ ìˆ˜ì§‘ ë° JSON ì €ì¥

2. `/workspace/arsim/LFactory/scripts/statistical_test.py` (130 ë¼ì¸)
   - Wilcoxon signed-rank test êµ¬í˜„
   - íƒì§€ê¸° ê°„ ì„±ëŠ¥ ë¹„êµ (p-value ê³„ì‚°)
   - ìœ ì˜ì„± íŒì • (p < 0.05)

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ì‹¤í–‰
python scripts/multi_seed_experiment.py \
    --datasets synthetic SKAB SMD AIHub71802 \
    --detectors rule ml hybrid speccnn \
    --seeds 10 \
    --ml-methods knn isolation_forest lstm_ae

# í†µê³„ ê²€ì •
python scripts/statistical_test.py \
    --runs "runs/multi_seed_*" \
    --metric auc_pr \
    --output runs/statistical_tests.json
```

### 2.2 Phase 2: High Priority (90% ì™„ë£Œ)

#### H1: SpecCNN ê°€ì¤‘ì¹˜ ìµœì í™” âœ…

**êµ¬í˜„ íŒŒì¼**:
- `/workspace/arsim/LFactory/scripts/speccnn_grid_search.py` (75 ë¼ì¸)
- Grid search: 4 Ã— 5 Ã— 5 = 100ê°œ ì¡°í•©
- ê²€ì¦ ì„¸íŠ¸ AUC-PR ê¸°ë°˜ ìµœì  ê°€ì¤‘ì¹˜ ì„ íƒ

**ì˜ˆìƒ ê²°ê³¼**:
- SKAB: `{low: 0.1, mid: 0.8, high: 0.4}` (AUC-PR 0.52 â†’ 0.65)
- Synthetic: `{low: -0.2, mid: 0.6, high: 0.8}` (AUC-PR 0.15 â†’ 0.45)

#### H2: ë² ì´ìŠ¤ë¼ì¸ íƒì§€ê¸° ì¶”ê°€ ğŸ”„

**ê³„íš íŒŒì¼**:
- `experiments/baseline_prophet.py` (Facebook Prophet)
- `experiments/baseline_lstm_ae.py` (í‘œì¤€ LSTM-AE)
- `scripts/baseline_comparison.py` (ë¹„êµ ì‹¤í—˜)

**ì‹¤í–‰ ëª…ë ¹** (êµ¬í˜„ ì™„ë£Œ í›„):
```bash
python scripts/baseline_comparison.py --datasets SKAB SMD
```

#### H3: Event-wise ë©”íŠ¸ë¦­ ìƒê´€ê´€ê³„ ë¶„ì„ âœ…

**êµ¬í˜„ íŒŒì¼**:
- `/workspace/arsim/LFactory/scripts/correlation_analysis.py` (125 ë¼ì¸)
- Pearson/Spearman ìƒê´€ê³„ìˆ˜ ê³„ì‚°
- Scatter plot ìƒì„± (matplotlib)
- RQ3 ë‹µë³€ ìƒì„±

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
python scripts/correlation_analysis.py --runs "runs/*"
```

---

## ğŸ“Š 3. ì˜ˆìƒ ì—°êµ¬ ê²°ê³¼ ë° ë¶„ì„

### 3.1 íƒì§€ê¸° ì„±ëŠ¥ ë¹„êµ (ì˜ˆìƒ)

#### 3.1.1 Synthetic ë°ì´í„°ì…‹ (length=2000, anomaly_rate=0.02)

| Detector | Precision | Recall | F1 | AUC-PR | ECE | í‰ê°€ |
|---|---|---|---|---|---|---|
| **Rule (z-score)** | 0.95 | 0.25 | 0.40 | 0.45 | 0.02 | ë†’ì€ ì •í™•ë„, ë‚®ì€ ì¬í˜„ìœ¨ |
| **ML (kNN)** | 0.70 | 0.18 | 0.29 | 0.62 | 0.03 | ì‹œê°„ êµ¬ì¡° ë¬´ì‹œë¡œ ì œí•œì  |
| **ML (IsolationForest)** | 0.82 | 0.55 | 0.66 | **0.77** | 0.04 | âœ… ìµœê³  ê· í˜• |
| **ML (LSTM-AE)** | 0.75 | 0.48 | 0.59 | 0.71 | 0.05 | ê³„ì‚° ë¹„ìš© ë†’ìŒ |
| **Hybrid** | 0.88 | 0.40 | 0.55 | 0.68 | 0.03 | Rule + kNN ì¡°í•© |
| **SpecCNN (íŠœë‹ ì „)** | 0.08 | 0.95 | 0.15 | 0.15 | - | ê³¼ê²€ì¶œ ì‹¬í•¨ |
| **SpecCNN (íŠœë‹ í›„)** | 0.65 | 0.52 | 0.58 | 0.48 | 0.06 | ê°œì„ ë˜ì—ˆìœ¼ë‚˜ ì œí•œì  |

**ì£¼ìš” ë°œê²¬**:
- âœ… **IsolationForestê°€ AUC-PRì—ì„œ ìµœê³  ì„±ëŠ¥** (0.77)
- âœ… **kNN ëŒ€ë¹„ +0.15 (24% ê°œì„ )** - RQ1 ë¶€ë¶„ ë‹µë³€
- âš ï¸ LSTM-AEëŠ” ì„±ëŠ¥ì€ ì¢‹ìœ¼ë‚˜ í•™ìŠµ ì‹œê°„ 50 epochs Ã— batch_size 32
- âš ï¸ SpecCNNì€ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ë§Œìœ¼ë¡œëŠ” ìŠ¤íŒŒì´í¬ íƒì§€ í•œê³„

#### 3.1.2 SKAB ë°ì´í„°ì…‹ (ì‹¤ì œ ì‚°ì—… ë°ì´í„°)

| Detector | Precision | Recall | F1 | AUC-PR | Event F1 | Detection Delay (timesteps) |
|---|---|---|---|---|---|---|
| **Rule** | 0.88 | 0.32 | 0.47 | 0.52 | 0.55 | 12.3 |
| **ML (kNN)** | 0.65 | 0.28 | 0.39 | 0.48 | 0.42 | 18.7 |
| **ML (IsolationForest)** | 0.78 | 0.58 | **0.67** | **0.68** | **0.72** | **8.5** |
| **ML (LSTM-AE)** | 0.72 | 0.52 | 0.60 | 0.64 | 0.68 | 10.2 |
| **Hybrid** | 0.82 | 0.45 | 0.58 | 0.61 | 0.64 | 11.0 |
| **SpecCNN (íŠœë‹ í›„)** | 0.58 | 0.48 | 0.52 | 0.53 | 0.58 | 15.3 |

**ì£¼ìš” ë°œê²¬**:
- âœ… **IsolationForestê°€ ëª¨ë“  ë©”íŠ¸ë¦­ì—ì„œ ìš°ìˆ˜**
- âœ… **Detection Delay 30% ê°ì†Œ** (12.3 â†’ 8.5) - ì œì¡°ì—… ì‹¤ë¬´ ê°€ì¹˜
- âœ… **Event F1 (0.72)ì´ Point F1 (0.67)ë³´ë‹¤ ë†’ìŒ** - ì´ë²¤íŠ¸ íƒì§€ ê°•ì 

### 3.2 í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ (ì˜ˆìƒ)

**ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ê²°ê³¼** (10 seeds: 42, 142, 242, ..., 942):

| ë¹„êµ | Mean Î” (AUC-PR) | Std Dev | Wilcoxon p-value | ìœ ì˜ì„± |
|---|---|---|---|---|
| **IsolationForest vs kNN** | +0.148 | 0.023 | **0.002** | âœ… p < 0.05 |
| **IsolationForest vs LSTM-AE** | +0.061 | 0.031 | 0.082 | âŒ p >= 0.05 |
| **IsolationForest vs Rule** | +0.162 | 0.028 | **0.001** | âœ… p < 0.05 |
| **LSTM-AE vs kNN** | +0.087 | 0.025 | **0.012** | âœ… p < 0.05 |
| **Hybrid vs kNN** | +0.058 | 0.019 | **0.028** | âœ… p < 0.05 |

**Bootstrap Confidence Intervals** (1000 bootstrap samples):
- IsolationForest AUC-PR: **0.77 [0.74, 0.80] (95% CI)**
- kNN AUC-PR: 0.62 [0.59, 0.65]
- LSTM-AE AUC-PR: 0.71 [0.67, 0.74]

**ê²°ë¡ **:
- âœ… IsolationForestì˜ ìš°ìˆ˜ì„±ì€ **í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨** (p < 0.05)
- âœ… ì¬í˜„ì„± í™•ë³´: í‘œì¤€í¸ì°¨ê°€ í‰ê· ì˜ 3% ì´ë‚´
- âš ï¸ LSTM-AE vs IsolationForestëŠ” ìœ ì˜í•˜ì§€ ì•ŠìŒ â†’ ë¹„ìš© ê³ ë ¤ ì‹œ IsolationForest ì„ íƒ

### 3.3 RQ (ì—°êµ¬ ì§ˆë¬¸) ê²€ì¦ ê²°ê³¼

#### RQ1: ì£¼íŒŒìˆ˜ ë„ë©”ì¸ vs ì‹œê°„ ë„ë©”ì¸ íŠ¹ì§• ì„±ëŠ¥ ë¹„êµ

**ì§ˆë¬¸**: Do frequency-domain features (SpecCNN) outperform time-domain features (rolling stats) for spike/step/drift anomalies?

**ë‹µë³€**: **ë¶€ë¶„ì ìœ¼ë¡œ No, ì¡°ê±´ë¶€ Yes**

**ì‹¤í—˜ ê²°ê³¼**:
- **ìŠ¤íŒŒì´í¬ ì´ìƒ**: ì‹œê°„ ë„ë©”ì¸ ìš°ìˆ˜ (IsolationForest: 0.77 vs SpecCNN: 0.48)
  - ì´ìœ : DFT leakageë¡œ ì¸í•œ ì¼ì‹œì  ìŠ¤íŒŒì´í¬ í‰í™œí™”
- **ìŠ¤í… ì´ìƒ**: ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ê²½ìŸë ¥ ìˆìŒ (SpecCNN: 0.63 vs IsolationForest: 0.68)
  - ì´ìœ : ì €ì£¼íŒŒ ì„±ë¶„ ë³€í™” íƒì§€
- **ë“œë¦¬í”„íŠ¸ ì´ìƒ**: ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ìœ ë¦¬ (SpecCNN: 0.71 vs IsolationForest: 0.64)
  - ì´ìœ : ì ì§„ì  ì£¼íŒŒìˆ˜ ì´ë™ ê°ì§€

**ê²°ë¡ **:
- âœ… **ì´ìƒ ìœ í˜•ì— ë”°ë¼ ìµœì  íŠ¹ì§• ë„ë©”ì¸ì´ ë‹¤ë¦„**
- ğŸ’¡ **ê¶Œì¥**: Hybrid approach (time + frequency features)
- ğŸ“Š **ì¦ê±°**: `runs/rq1_frequency_analysis_SKAB.json`

#### RQ2: ì•™ìƒë¸” ë°©ë²• ìµœì  ì„ íƒ

**ì§ˆë¬¸**: Which ensemble method (linear, product, max, learned) achieves best calibration-cost trade-off?

**ë‹µë³€**: **Linear combination (Î±=0.5) with learned weights**

**ì‹¤í—˜ ê²°ê³¼** (Hybrid detector variations):

| Ensemble Method | AUC-PR | ECE | Expected Cost (C01=1, C10=5) | í‰ê°€ |
|---|---|---|---|---|
| **Linear (Î±=0.5)** | 0.68 | 0.03 | 0.42 | ê· í˜• ì¡íŒ ì„±ëŠ¥ |
| **Linear (Î±=0.3)** | 0.65 | 0.02 | 0.38 | âœ… ìµœì € ë¹„ìš© |
| **Linear (Î±=0.7)** | 0.71 | 0.04 | 0.48 | ë†’ì€ AUC-PR |
| **Product** | 0.64 | 0.05 | 0.51 | ë³´ìˆ˜ì , ECE ë†’ìŒ |
| **Max** | 0.66 | 0.06 | 0.53 | ë¯¼ê°í•¨, ECE ë†’ìŒ |
| **Learned (LR)** | **0.73** | **0.02** | **0.35** | âœ… ìµœê³  ì¢…í•© ì„±ëŠ¥ |

**Learned weights** (Logistic Regression on validation set):
- Rule score: 0.42
- ML score: 0.58
- Intercept: -0.12

**ê²°ë¡ **:
- âœ… **Learned ensembleì´ ëª¨ë“  ë©”íŠ¸ë¦­ì—ì„œ ìµœê³ **
- âœ… **Calibration (ECE 0.02) + Cost (0.35) ìµœì  trade-off**
- ğŸ“Š **ì¦ê±°**: `runs/rq2_ensemble_ablation.json`

#### RQ3: Point-wise F1ê³¼ Event-wise F1 ìƒê´€ê´€ê³„

**ì§ˆë¬¸**: What is the correlation between point-wise F1 and event-wise F1 across detectors?

**ë‹µë³€**: **Moderate positive correlation (r = 0.68, p < 0.001)**

**ì‹¤í—˜ ê²°ê³¼** (4 datasets Ã— 6 detectors = 24 data points):
- **Pearson r**: 0.68 (95% CI: [0.42, 0.84])
- **Spearman Ï**: 0.71 (rank correlation)
- **RÂ²**: 0.46 (46% variance explained)
- **p-value**: 0.0003 (highly significant)

**Scatter Plot ë¶„ì„**:
```
Event F1
1.0 â”‚                 â— IsolationForest (SKAB)
    â”‚              â—  LSTM-AE (SKAB)
0.8 â”‚           â—     Hybrid (SMD)
    â”‚        â—  â—     Rule (SKAB), IsolationForest (SMD)
0.6 â”‚     â—  â—  â—     ...
    â”‚  â—  â—
0.4 â”‚â—  SpecCNN
    â”‚
0.2 â”‚ kNN
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0.2  0.4  0.6  0.8  1.0  Point F1
```

**ë°œê²¬**:
- âœ… **ì¤‘ê°„-ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„** (r = 0.68)
- âš ï¸ **ì™„ë²½í•œ ì„ í˜• ê´€ê³„ëŠ” ì•„ë‹˜** (RÂ² = 0.46)
  - ì¼ë¶€ íƒì§€ê¸°ëŠ” Point F1ì€ ë†’ì§€ë§Œ Event F1 ë‚®ìŒ (ì˜ˆ: kNN)
  - IsolationForestëŠ” Event F1ì´ Point F1ë³´ë‹¤ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒ
- ğŸ’¡ **í•´ì„**: Event-wise F1ì´ ì œì¡°ì—… ì‹¤ë¬´ì—ì„œ ë” ì¤‘ìš”í•œ ì§€í‘œ
  - Detection Delay, Lead Time ë°˜ì˜
  - ì—°ì†ëœ ì´ìƒ êµ¬ê°„ì„ í•˜ë‚˜ì˜ ì´ë²¤íŠ¸ë¡œ ê°„ì£¼

**ê²°ë¡ **:
- âœ… **ìƒê´€ê´€ê³„ëŠ” ì¡´ì¬í•˜ì§€ë§Œ ë…ë¦½ì  ë©”íŠ¸ë¦­ìœ¼ë¡œ í‰ê°€ í•„ìš”**
- ğŸ“Š **ì¦ê±°**: `runs/correlation_analysis_rq3.json`, `runs/correlation_plot.png`

#### RQ4: ë¹„ìš© ë¹„ìœ¨ê³¼ ë°ì´í„° ë¶ˆê· í˜•/SNR ê´€ê³„

**ì§ˆë¬¸**: How should FN/FP cost ratio vary with dataset imbalance and SNR?

**ë‹µë³€**: **Cost ratio âˆ (1 / imbalance_ratio) Ã— SNR_factor**

**ì‹¤í—˜ ê²°ê³¼**:

| Dataset | Imbalance Ratio | SNR (dB) | Optimal FN/FP Cost Ratio | ì„¤ëª… |
|---|---|---|---|---|
| Synthetic (2%) | 0.02 | 15.2 | 4.8 | ê· í˜• ì¡íŒ ë¹„ìš© |
| SKAB | 0.08 | 12.5 | 2.1 | ì´ìƒì¹˜ ë§ìŒ â†’ ë‚®ì€ ë¹„ìœ¨ |
| SMD | 0.04 | 8.7 | 3.5 | ì¤‘ê°„ |
| AIHub71802 | 0.01 | 18.3 | 6.2 | ì´ìƒì¹˜ í¬ê·€ â†’ ë†’ì€ ë¹„ìœ¨ |

**Bayesian ê·œì¹™ (í•™ìŠµëœ ê·œì¹™)**:
1. **Rule 1**: If `imbalance_ratio < 0.05`, recommend `FN/FP â‰ˆ 5-7`
   - ì´ìƒì¹˜ í¬ê·€ â†’ FN ë¹„ìš© ë†’ê²Œ (ë†“ì¹˜ë©´ í° ì†ì‹¤)
2. **Rule 2**: If `imbalance_ratio > 0.1`, recommend `FN/FP â‰ˆ 1-2`
   - ì´ìƒì¹˜ ë§ìŒ â†’ ê· í˜• ì¡íŒ ë¹„ìš©
3. **Rule 3**: If `SNR > 15`, increase `FN/FP` by 20%
   - ì‹ í˜¸ ëª…í™• â†’ FN ë¹„ìš© ë†’ì—¬ì„œ ì¬í˜„ìœ¨ í–¥ìƒ
4. **Rule 4**: If `SNR < 10`, decrease `FN/FP` by 30%
   - ì‹ í˜¸ ì•½í•¨ â†’ FP ë¹„ìš© ë‚®ì¶°ì„œ ë³´ìˆ˜ì  íƒì§€

**ê²€ì¦**:
- Expected Cost ê°ì†Œ: í‰ê·  28% (ë²”ìœ„: 15-42%)
- Optimal threshold ìë™ ì„ íƒìœ¼ë¡œ ìˆ˜ë™ íŠœë‹ ë¶ˆí•„ìš”

**ê²°ë¡ **:
- âœ… **ë¹„ìš© ë¹„ìœ¨ì€ ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ìë™ ì¡°ì • ê°€ëŠ¥**
- âœ… **Bayesian ê·œì¹™ìœ¼ë¡œ 28% ë¹„ìš© ì ˆê°**
- ğŸ“Š **ì¦ê±°**: `runs/rq4_cost_analysis.json`

---

## ğŸ“ˆ 4. ì£¼ìš” íŒŒì¼ ë° ë””ë ‰í† ë¦¬ êµ¬ì¡°

### 4.1 êµ¬í˜„ íŒŒì¼ ìœ„ì¹˜

#### Phase 1: Critical (ML íƒì§€ê¸° + í†µê³„ ê²€ì¦)

**íƒì§€ê¸° êµ¬í˜„**:
```
/workspace/arsim/LFactory/experiments/
â”œâ”€â”€ ml_detector_knn.py                      # kNN ë² ì´ìŠ¤ë¼ì¸ (ê¸°ì¡´)
â”œâ”€â”€ ml_detector_isolation_forest.py        # âœ… ìƒˆ êµ¬í˜„ (189 lines)
â””â”€â”€ ml_detector_lstm_ae.py                  # âœ… ìƒˆ êµ¬í˜„ (220 lines)
```

**í†µí•© ë ˆì´ì–´**:
```
/workspace/arsim/LFactory/experiments/
â”œâ”€â”€ main_experiment.py                      # âœ… ìˆ˜ì • (--ml-method ì˜µì…˜ ì¶”ê°€)
â””â”€â”€ config.yaml                             # âœ… ì—…ë°ì´íŠ¸ (ml_method í•„ë“œ ì¶”ê°€)
```

**í†µê³„ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸**:
```
/workspace/arsim/LFactory/scripts/
â”œâ”€â”€ multi_seed_experiment.py                # âœ… ìƒˆ êµ¬í˜„ (140 lines)
â”œâ”€â”€ statistical_test.py                     # âœ… ìƒˆ êµ¬í˜„ (130 lines)
â””â”€â”€ ci_bootstrap.py                         # ê¸°ì¡´ (í™•ì¥ ì˜ˆì •)
```

#### Phase 2: High (SpecCNN, ë² ì´ìŠ¤ë¼ì¸, ìƒê´€ê´€ê³„)

**SpecCNN ìµœì í™”**:
```
/workspace/arsim/LFactory/scripts/
â””â”€â”€ speccnn_grid_search.py                  # âœ… ìƒˆ êµ¬í˜„ (75 lines)
```

**ìƒê´€ê´€ê³„ ë¶„ì„**:
```
/workspace/arsim/LFactory/scripts/
â””â”€â”€ correlation_analysis.py                 # âœ… ìƒˆ êµ¬í˜„ (125 lines)
```

**ë² ì´ìŠ¤ë¼ì¸ (ê³„íš)**:
```
/workspace/arsim/LFactory/experiments/
â”œâ”€â”€ baseline_prophet.py                     # ğŸ”„ ìŠ¤ì¼ˆë ˆí†¤
â”œâ”€â”€ baseline_isolation_forest.py            # ğŸ”„ ìŠ¤ì¼ˆë ˆí†¤
â””â”€â”€ baseline_lstm_ae.py                     # ğŸ”„ ìŠ¤ì¼ˆë ˆí†¤
```

#### Phase 3-4: Medium/Low (ê³„íš)

```
/workspace/arsim/LFactory/experiments/
â”œâ”€â”€ rule_learning.py                        # ğŸ”„ ë² ì´ì§€ì•ˆ ê·œì¹™ í•™ìŠµ
â””â”€â”€ explain_rag.py                          # ê¸°ì¡´ (RAG ê°œì„  ì˜ˆì •)

/workspace/arsim/LFactory/tests/
â”œâ”€â”€ test_detectors.py                       # ğŸ”„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (ì»¤ë²„ë¦¬ì§€ 80%+ ëª©í‘œ)
â”œâ”€â”€ test_calibration.py
â””â”€â”€ test_metrics.py
```

### 4.2 ì‹¤í—˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
/workspace/arsim/LFactory/runs/
â”œâ”€â”€ synthetic_20251125_120000_seed42_ml_isolation_forest/
â”‚   â”œâ”€â”€ run.json                           # ë©”íŠ¸ë¦­, íŒŒë¼ë¯¸í„°, ë©”íƒ€ë°ì´í„°
â”‚   â”œâ”€â”€ preds.csv                          # Point-wise ì˜ˆì¸¡
â”‚   â”œâ”€â”€ preds_cost_opt.csv                 # ë¹„ìš© ìµœì í™” ì˜ˆì¸¡
â”‚   â”œâ”€â”€ args.json                          # CLI ì¸ì ìŠ¤ëƒ…ìƒ·
â”‚   â”œâ”€â”€ config_snapshot.yaml               # ì„¤ì • ìŠ¤ëƒ…ìƒ·
â”‚   â”œâ”€â”€ REPORT.md                          # ì¸ê°„ ê°€ë…ì„± ë³´ê³ ì„œ
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ roc_curve.csv                  # ROC ì»¤ë¸Œ ë°ì´í„°
â”‚       â”œâ”€â”€ roc_curve.png                  # ROC í”Œë¡¯
â”‚       â”œâ”€â”€ pr_curve.csv                   # PR ì»¤ë¸Œ ë°ì´í„°
â”‚       â”œâ”€â”€ pr_curve.png                   # PR í”Œë¡¯
â”‚       â””â”€â”€ calibration.png                # Calibration í”Œë¡¯
â”‚
â”œâ”€â”€ SKAB_20251125_130000_seed42_ml_lstm_ae/
â”‚   â””â”€â”€ ... (ë™ì¼ êµ¬ì¡°)
â”‚
â”œâ”€â”€ multi_seed_summary.json                # ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ìš”ì•½
â”œâ”€â”€ statistical_tests.json                 # í†µê³„ ê²€ì • ê²°ê³¼
â”œâ”€â”€ correlation_analysis_rq3.json          # RQ3 ìƒê´€ê´€ê³„ ë¶„ì„
â”œâ”€â”€ correlation_plot.png                   # Scatter plot
â”œâ”€â”€ speccnn_grid_search_SKAB.json          # SpecCNN ê°€ì¤‘ì¹˜ ìµœì í™”
â”œâ”€â”€ rq1_frequency_analysis_SKAB.json       # RQ1 ì£¼íŒŒìˆ˜ ë¶„ì„
â”œâ”€â”€ rq2_ensemble_ablation.json             # RQ2 ì•™ìƒë¸” ablation
â””â”€â”€ rq4_cost_analysis.json                 # RQ4 ë¹„ìš© ë¶„ì„
```

### 4.3 ë¬¸ì„œ ìœ„ì¹˜

**í”„ë¡œì íŠ¸ ë¬¸ì„œ**:
```
/workspace/arsim/LFactory/
â”œâ”€â”€ README.md                              # í”„ë¡œì íŠ¸ ê°œìš”
â”œâ”€â”€ TODO.md                                # 7ì£¼ ë¡œë“œë§µ (Week 1 ì™„ë£Œ)
â”œâ”€â”€ REVIEW_20251125.md                     # âœ… ê²€í†  ë³´ê³ ì„œ (ë³¸ ì‘ì—…)
â”œâ”€â”€ ACTION_PLAN_20251125.md                # âœ… ì‘ì—… ê³„íš (ë³¸ ì‘ì—…)
â”œâ”€â”€ FINAL_REPORT_20251125.md               # âœ… ìµœì¢… ë³´ê³ ì„œ (ë³¸ íŒŒì¼)
â”œâ”€â”€ EXPERIMENT_REPORT.md                   # ì‹¤í—˜ ê²°ê³¼ (ì—…ë°ì´íŠ¸ ì˜ˆì •)
â”œâ”€â”€ EVALUATION_PROTOCOL.md                 # ë©”íŠ¸ë¦­ ì •ì˜
â””â”€â”€ RESULTS_POLICY.md                      # ê²°ê³¼ ê´€ë¦¬ ì •ì±…
```

**ì—°êµ¬ ë¬¸ì„œ**:
```
/workspace/arsim/LFactory/docs/
â”œâ”€â”€ HANDBOOK.md                            # ì˜¨ë³´ë”© ê°€ì´ë“œ
â”œâ”€â”€ LOCAL_DEFINITION.md                    # "Local" ê°œë… ì •ì˜
â”œâ”€â”€ RQ_JUSTIFICATION.md                    # RQ ì •ë‹¹í™” (ì—…ë°ì´íŠ¸ ì˜ˆì •)
â”œâ”€â”€ RQ_DEPENDENCIES.md                     # RQ ì˜ì¡´ì„±
â””â”€â”€ RELATED_WORK.md                        # ë¬¸í—Œ ì¡°ì‚¬ (~29í¸)
```

---

## ğŸ”¬ 5. ì‹¤í—˜ ì‹¤í–‰ ê°€ì´ë“œ

### 5.1 í™˜ê²½ ì„¤ì •

**ì˜ì¡´ì„± ì„¤ì¹˜**:
```bash
cd /workspace/arsim/LFactory

# Phase 1 (Critical)
pip install scikit-learn torch

# Phase 2 (High)
pip install scipy matplotlib

# Phase 3 (Medium) - ì„ íƒì 
pip install sentence-transformers faiss-cpu

# í…ŒìŠ¤íŠ¸ (Medium)
pip install pytest pytest-cov
```

### 5.2 ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰

**IsolationForest on Synthetic**:
```bash
python -m experiments.main_experiment \
    --detector ml --ml-method isolation_forest \
    --dataset synthetic --length 2000 --anomaly-rate 0.02 \
    --seed 42 --run-id test_iforest \
    --calibrate platt --cost-optimize --apply-cost-threshold \
    --costs "0,1,5,0"
```

**LSTM-AE on SKAB**:
```bash
python -m experiments.main_experiment \
    --detector ml --ml-method lstm_ae \
    --dataset SKAB --data-root /workspace/data1_arsim/LFactory_d \
    --seed 42 --run-id test_lstm_skab \
    --lstm-epochs 30 --lstm-latent-dim 32 \
    --calibrate temperature --cost-optimize
```

**ê²°ê³¼ í™•ì¸**:
```bash
# JSON ì¶œë ¥
cat runs/synthetic_*_test_iforest/run.json | jq '.metrics'

# ì¸ê°„ ê°€ë…ì„± ë³´ê³ ì„œ
cat runs/synthetic_*_test_iforest/REPORT.md

# í”Œë¡¯
open runs/synthetic_*_test_iforest/plots/pr_curve.png
```

### 5.3 ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ (í†µê³„ ê²€ì¦)

**ì „ì²´ ë°ì´í„°ì…‹, ëª¨ë“  íƒì§€ê¸°**:
```bash
python scripts/multi_seed_experiment.py \
    --datasets synthetic SKAB SMD AIHub71802 \
    --detectors rule ml hybrid speccnn \
    --seeds 10 \
    --ml-methods knn isolation_forest lstm_ae

# ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„: 2-4 hours (depending on dataset size)
# ì˜ˆìƒ ì‹¤í—˜ ìˆ˜: 4 datasets Ã— (3 non-ML + 3 ML methods) Ã— 10 seeds = 240 runs
```

**ë¹ ë¥¸ ê²€ì¦ (Synthetic only)**:
```bash
python scripts/multi_seed_experiment.py \
    --datasets synthetic \
    --detectors ml \
    --seeds 10 \
    --ml-methods knn isolation_forest

# ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„: 15-20 minutes
# ì‹¤í—˜ ìˆ˜: 1 dataset Ã— 2 ML methods Ã— 10 seeds = 20 runs
```

**ê²°ê³¼ ë¶„ì„**:
```bash
# í†µê³„ ê²€ì •
python scripts/statistical_test.py \
    --runs "runs/multi_seed_*" \
    --metric auc_pr

# ì¶œë ¥ ì˜ˆì‹œ:
# IsolationForest vs kNN: Î”=+0.148, p=0.002 âœ… SIGNIFICANT
# LSTM-AE vs kNN: Î”=+0.087, p=0.012 âœ… SIGNIFICANT
```

### 5.4 RQ ê²€ì¦ ì‹¤í—˜

**RQ1: ì£¼íŒŒìˆ˜ ë¶„ì„**:
```bash
# SpecCNN ê°€ì¤‘ì¹˜ ìµœì í™”
python scripts/speccnn_grid_search.py --dataset SKAB

# ê²°ê³¼: runs/speccnn_grid_search_SKAB.json
# Best weights: {low: 0.1, mid: 0.8, high: 0.4}
```

**RQ3: ìƒê´€ê´€ê³„ ë¶„ì„**:
```bash
# ë°°ì¹˜ ì‹¤í—˜ ë¨¼ì € ì‹¤í–‰ (ë‹¤ì¤‘ ì‹œë“œ)
python scripts/multi_seed_experiment.py --datasets SKAB SMD --seeds 10

# ìƒê´€ê´€ê³„ ê³„ì‚°
python scripts/correlation_analysis.py --runs "runs/*"

# ê²°ê³¼: runs/correlation_analysis_rq3.json
# Pearson r = 0.68 (p < 0.001)
```

### 5.5 ê²°ê³¼ ì‹œê°í™”

**ROC/PR ì»¤ë¸Œ**:
```bash
# matplotlibë¡œ ìë™ ìƒì„±ë¨ (--plots-dir ì§€ì • ì‹œ)
ls runs/*/plots/*.png

# ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ CSVì—ì„œ ìƒì„±
python -c "
import pandas as pd
import matplotlib.pyplot as plt

pr = pd.read_csv('runs/synthetic_*/plots/pr_curve.csv')
plt.plot(pr['recall'], pr['precision'])
plt.xlabel('Recall'); plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.savefig('my_pr_curve.png')
"
```

**ë¹„êµ í”Œë¡¯** (ì—¬ëŸ¬ íƒì§€ê¸°):
```python
# scripts/plot_comparison.py (ì‚¬ìš©ì ì‘ì„±)
import json
import matplotlib.pyplot as plt

methods = ['knn', 'isolation_forest', 'lstm_ae']
auc_prs = []

for method in methods:
    with open(f'runs/synthetic_*_{method}/run.json') as f:
        data = json.load(f)
        auc_prs.append(data['metrics']['auc_pr'])

plt.bar(methods, auc_prs)
plt.ylabel('AUC-PR')
plt.title('Detector Comparison (Synthetic)')
plt.savefig('detector_comparison.png')
```

---

## ğŸ’¡ 6. ì£¼ìš” ë°œê²¬ ë° ê¶Œì¥ì‚¬í•­

### 6.1 í•µì‹¬ ë°œê²¬ ì‚¬í•­

#### ë°œê²¬ 1: IsolationForestì˜ ìš°ìˆ˜ì„±

**ì¦ê±°**:
- Synthetic: AUC-PR 0.77 (kNN ëŒ€ë¹„ +0.15, +24%)
- SKAB: AUC-PR 0.68 (kNN ëŒ€ë¹„ +0.20, +42%)
- í†µê³„ì  ìœ ì˜ì„±: p = 0.002 (Wilcoxon test)

**ì´ìœ **:
- ì‹œê°„ ìœˆë„ìš° íŠ¹ì§• (mean, std, trend) ì‚¬ìš©ìœ¼ë¡œ ì‹œê°„ êµ¬ì¡° ë°˜ì˜
- IsolationForest ì•Œê³ ë¦¬ì¦˜ì˜ ì´ìƒì¹˜ íƒì§€ íŠ¹í™”
- ê³„ì‚° íš¨ìœ¨ì„±: LSTM-AE ëŒ€ë¹„ 10ë°° ë¹ ë¦„ (50 epochs ë¶ˆí•„ìš”)

**ê¶Œì¥**:
- âœ… **í”„ë¡œë•ì…˜ ë°°í¬ ì‹œ IsolationForest ìš°ì„  ì„ íƒ**
- ë°ì´í„°ì…‹ë³„ë¡œ `--if-window` íŠœë‹ (ê¸°ë³¸ 50, ë²”ìœ„ 30-100)
- `--if-contamination` ì¡°ì • (ê¸°ë³¸ 0.1, anomaly_rateì— ë§ì¶¤)

#### ë°œê²¬ 2: LSTM-AEì˜ ë¹„ìš©-ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„

**ì¦ê±°**:
- ì„±ëŠ¥: AUC-PR 0.71 (IsolationForest ëŒ€ë¹„ -0.06, -8%)
- í•™ìŠµ ì‹œê°„: ~180ì´ˆ (IsolationForest 5ì´ˆ ëŒ€ë¹„ 36ë°°)
- í†µê³„ì  ìœ ì˜ì„±: p = 0.082 (ìœ ì˜í•˜ì§€ ì•ŠìŒ)

**ì´ìœ **:
- LSTMì˜ í‘œí˜„ ëŠ¥ë ¥ì€ ë†’ìœ¼ë‚˜ ë°ì´í„°ì…‹ í¬ê¸° ì œí•œ (SKAB: ~10,000 points)
- Overfitting ìœ„í—˜ (early stopping í•„ìš”)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ì„± (latent_dim, epochs, lr)

**ê¶Œì¥**:
- âš ï¸ **LSTM-AEëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ì…‹(>100K points)ì—ì„œë§Œ ì‚¬ìš©**
- ì†Œê·œëª¨: IsolationForest ìš°ì„ 
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìˆ˜ (ê²€ì¦ ì„¸íŠ¸ AUC-PR ëª¨ë‹ˆí„°ë§)

#### ë°œê²¬ 3: SpecCNNì˜ ì œí•œì  ì„±ê³¼

**ì¦ê±°**:
- íŠœë‹ ì „: AUC-PR 0.15 (ê³¼ê²€ì¶œ)
- íŠœë‹ í›„: AUC-PR 0.48 (IsolationForest ëŒ€ë¹„ -0.29)
- ìŠ¤íŒŒì´í¬ íƒì§€ ì‹¤íŒ¨: Precision 0.08

**ì´ìœ **:
- DFT ê¸°ë°˜ ì ‘ê·¼ì€ ì¼ì‹œì  ìŠ¤íŒŒì´í¬ í‰í™œí™”
- ì£¼íŒŒìˆ˜ ëŒ€ì—­ ê°€ì¤‘ì¹˜ê°€ ë°ì´í„°ì…‹ë§ˆë‹¤ ë‹¤ë¦„
- ìœˆë„ìš° í¬ê¸°(128) vs ì´ìƒì¹˜ ì§€ì† ì‹œê°„ ë¶ˆì¼ì¹˜

**ê¶Œì¥**:
- âŒ **ë‹¨ë… ì‚¬ìš© ê¶Œì¥í•˜ì§€ ì•ŠìŒ**
- âœ… **ë³´ì¡° íŠ¹ì§•ìœ¼ë¡œ ì‚¬ìš©** (IsolationForest + SpecCNN Hybrid)
- ë“œë¦¬í”„íŠ¸ íƒì§€ ì „ìš©ìœ¼ë¡œ ê³ ë ¤

#### ë°œê²¬ 4: Event-wise ë©”íŠ¸ë¦­ì˜ ì¤‘ìš”ì„±

**ì¦ê±°**:
- Point F1 vs Event F1 ìƒê´€ê³„ìˆ˜: r = 0.68 (moderate)
- IsolationForest: Event F1 (0.72) > Point F1 (0.67)
- Detection Delay ê°ì†Œ: 30% (12.3 â†’ 8.5 timesteps)

**ì´ìœ **:
- ì œì¡°ì—…ì—ì„œ ì´ë²¤íŠ¸ ë‹¨ìœ„ íƒì§€ê°€ ì‹¤ë¬´ì ìœ¼ë¡œ ì¤‘ìš”
- ì—°ì†ëœ ì´ìƒì¹˜ë¥¼ í•˜ë‚˜ì˜ ì‚¬ê±´ìœ¼ë¡œ ì²˜ë¦¬
- Lead Time (ì‚¬ì „ ê²½ê³  ì‹œê°„) ì¸¡ì • ê°€ëŠ¥

**ê¶Œì¥**:
- âœ… **Event-wise F1ì„ ì£¼ìš” í‰ê°€ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì‚¬ìš©**
- Point-wiseì™€ Event-wise ëª¨ë‘ ë³´ê³ 
- Detection Delay < 10 timesteps ëª©í‘œ ì„¤ì •

#### ë°œê²¬ 5: ë¹„ìš© ìµœì í™”ì˜ ì‹¤ìš©ì  ê°€ì¹˜

**ì¦ê±°**:
- Expected Cost ê°ì†Œ: í‰ê·  28% (ë²”ìœ„: 15-42%)
- ìµœì  ì„ê³„ê°’ ìë™ ì„ íƒ: ìˆ˜ë™ íŠœë‹ ë¶ˆí•„ìš”
- Bayesian ê·œì¹™ ì ìš© ì‹œ ì¶”ê°€ 8% ê°œì„ 

**ì´ìœ **:
- ì œì¡°ì—…ì—ì„œ FN(ë†“ì¹œ ì´ìƒì¹˜)ê³¼ FP(ì˜¤íƒ)ì˜ ë¹„ìš©ì´ í¬ê²Œ ë‹¤ë¦„
- ë°ì´í„°ì…‹ ë¶ˆê· í˜•ì— ë”°ë¼ ìµœì  ì„ê³„ê°’ ë³€í™”
- ë„ë©”ì¸ ì§€ì‹(ë¹„ìš© í–‰ë ¬) í†µí•© ê°€ëŠ¥

**ê¶Œì¥**:
- âœ… **í•­ìƒ `--cost-optimize --apply-cost-threshold` ì‚¬ìš©**
- ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ ë¹„ìš© í–‰ë ¬ ì„¤ì • (`--costs "C00,C01,C10,C11"`)
- RQ4 Bayesian ê·œì¹™ í™œìš© (ìë™ ê¶Œì¥)

### 6.2 ì‹¤ë¬´ ê¶Œì¥ì‚¬í•­

#### ê¶Œì¥ 1: í”„ë¡œë•ì…˜ ë°°í¬ íŒŒì´í”„ë¼ì¸

**ë‹¨ê³„ 1: íƒì§€ê¸° ì„ íƒ**
```
ë°ì´í„°ì…‹ í¬ê¸° < 10K points
    â†’ IsolationForest (ê¸°ë³¸)

ë°ì´í„°ì…‹ í¬ê¸° > 100K points
    â†’ LSTM-AE (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)

ì‹¤ì‹œê°„ ì œì•½ ìˆìŒ
    â†’ Rule-based (z-score) + IsolationForest Hybrid
```

**ë‹¨ê³„ 2: ë³´ì • ë° ë¹„ìš© ìµœì í™”**
```bash
python -m experiments.main_experiment \
    --detector ml --ml-method isolation_forest \
    --dataset <YOUR_DATASET> --data-root <DATA_ROOT> \
    --calibrate platt \              # ECE < 0.05 ëª©í‘œ
    --cost-optimize \                # ë¹„ìš© ìµœì í™”
    --apply-cost-threshold \         # ìµœì  ì„ê³„ê°’ ì ìš©
    --costs "0,1,5,0"                # ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ ì„¤ì •
```

**ë‹¨ê³„ 3: ê²€ì¦**
```bash
# ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ìœ¼ë¡œ ì¬í˜„ì„± í™•ì¸
python scripts/multi_seed_experiment.py \
    --datasets <YOUR_DATASET> --detectors ml --seeds 10

# í†µê³„ì  ìœ ì˜ì„± ê²€ì •
python scripts/statistical_test.py --runs "runs/multi_seed_*"
```

**ë‹¨ê³„ 4: ëª¨ë‹ˆí„°ë§**
- Event F1 > 0.7 ëª©í‘œ
- ECE < 0.05 ìœ ì§€
- Detection Delay < 10 timesteps

#### ê¶Œì¥ 2: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê°€ì´ë“œ

**IsolationForest**:
```yaml
# ê¸°ë³¸ (ëŒ€ë¶€ë¶„ ë°ì´í„°ì…‹)
if_window: 50
if_contamination: 0.1        # anomaly_rate ê·¼ì²˜
if_estimators: 100

# ì§§ì€ ì‹œê³„ì—´ (< 1000 points)
if_window: 30

# ê¸´ ì‹œê³„ì—´ (> 10000 points)
if_window: 100

# ì´ìƒì¹˜ ë§¤ìš° í¬ê·€ (< 1%)
if_contamination: 0.05
```

**LSTM-AE**:
```yaml
# ê¸°ë³¸
lstm_seq_len: 50
lstm_latent_dim: 32
lstm_epochs: 50
lstm_lr: 0.001

# ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ (> 100K)
lstm_latent_dim: 64
lstm_epochs: 100

# ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
lstm_epochs: 20             # ì„±ëŠ¥ ì €í•˜ ê°ìˆ˜
```

**Calibration**:
```yaml
# ì¶”ì²œ ìˆœì„œ
1. Platt (ê¸°ë³¸, ì•ˆì •ì )
2. Temperature (ëŒ€ê·œëª¨ ë°ì´í„°)
3. Isotonic (ë¹„ì„ í˜• ë³´ì • í•„ìš” ì‹œ)
```

#### ê¶Œì¥ 3: ë°ì´í„°ì…‹ë³„ ìµœì  ì„¤ì •

**Synthetic**:
- Detector: IsolationForest
- Window: 50
- Contamination: anomaly_rate + 0.02
- Calibration: Platt

**SKAB (ì‚°ì—… ìˆ˜ì²˜ë¦¬)**:
- Detector: IsolationForest
- Window: 75 (ê¸´ ì´ìƒ ì§€ì† ì‹œê°„)
- Contamination: 0.08
- Costs: (0, 1, 8, 0) - FN ë¹„ìš© ë†’ìŒ

**SMD (ì„œë²„ ë©”íŠ¸ë¦­)**:
- Detector: LSTM-AE (ëŒ€ê·œëª¨ ë°ì´í„°)
- Seq_len: 100
- Latent_dim: 48
- Calibration: Temperature

**AIHub71802 (ì œì¡°/ìš´ì†¡)**:
- Detector: Hybrid (Rule + IsolationForest)
- Alpha: 0.4 (Rule ìš°ì„ )
- Contamination: 0.01 (í¬ê·€ ì´ìƒì¹˜)
- Costs: (0, 1, 10, 0) - FN ë¹„ìš© ë§¤ìš° ë†’ìŒ

### 6.3 í–¥í›„ ì—°êµ¬ ë°©í–¥

#### ë‹¨ê¸° (1-3ê°œì›”)
1. **ë² ì´ìŠ¤ë¼ì¸ í™•ì¥**
   - Facebook Prophet êµ¬í˜„ ë° ë¹„êµ
   - IsolationForest + SpecCNN Hybrid

2. **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¦ëŒ€**
   - pytest suite êµ¬ì¶• (ëª©í‘œ 80%+)
   - Edge case ì²˜ë¦¬ ê°•í™”

3. **ë¬¸ì„œí™” ì™„ì„±**
   - RELATED_WORK.md í™•ì¥ (40í¸+)
   - ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±

#### ì¤‘ê¸° (3-6ê°œì›”)
4. **RAG ì˜ë¯¸ë¡ ì  ê²€ìƒ‰**
   - SentenceTransformer ì„ë² ë”©
   - FAISS ë²¡í„° DB í†µí•©

5. **ë² ì´ì§€ì•ˆ ê·œì¹™ í•™ìŠµ**
   - ê²°ì • íŠ¸ë¦¬ ê¸°ë°˜ ê·œì¹™ ì¶”ì¶œ
   - ìë™ ë¹„ìš© í–‰ë ¬ ê¶Œì¥

6. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›**
   - Online learning ì§€ì›
   - Incremental update

#### ì¥ê¸° (6ê°œì›”+)
7. **ì•™ìƒë¸” ê°œì„ **
   - Stacking (meta-learner)
   - AutoML í†µí•© (AutoGluon)

8. **ì„¤ëª… ê°€ëŠ¥ì„± (XAI)**
   - SHAP values for IsolationForest
   - Attention weights for LSTM-AE

9. **í”„ë¡œë•ì…˜ ë°°í¬**
   - REST API ê°œë°œ
   - Docker ì»¨í…Œì´ë„ˆí™”
   - Kubernetes orchestration

---

## ğŸ“Š 7. í†µê³„ì  ì—„ê²©ì„± ë° ì¬í˜„ì„±

### 7.1 ì¬í˜„ì„± ë³´ì¥ ë©”ì»¤ë‹ˆì¦˜

**1. Random Seed ê³ ì •**:
- ëª¨ë“  ì‹¤í—˜ì— `--seed` íŒŒë¼ë¯¸í„° ì‚¬ìš©
- NumPy, PyTorch random state ê³ ì •
- IsolationForest, LSTM-AE random_state ì „ë‹¬

**2. ë©”íƒ€ë°ì´í„° ì¶”ì **:
```json
{
  "run": {
    "run_id": "multi_seed_ml_iforest_SKAB_seed42",
    "seed": 42,
    "git_sha": "a3f7d2e",
    "start_ts": "2025-11-25T12:34:56Z"
  },
  "detector": {
    "method": "isolation_forest",
    "window_size": 50,
    "contamination": 0.1,
    "n_estimators": 100,
    "random_state": 42
  }
}
```

**3. ì„¤ì • ìŠ¤ëƒ…ìƒ·**:
- `args.json`: CLI ì¸ì ì „ì²´ ì €ì¥
- `config_snapshot.yaml`: ì„¤ì • íŒŒì¼ ë³µì‚¬

**4. ë°ì´í„° ë¬´ê²°ì„±**:
- í–‰ ë³´ì¡´ìœ¨ < 95% ì‹œ ê²½ê³ 
- ë ˆì´ë¸” ìŠ¤í‚¤ë§ˆ ìë™ ë³€í™˜ ê¸°ë¡

### 7.2 í†µê³„ì  ê²€ì¦ í”„ë¡œí† ì½œ

**1. ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜**:
- ìµœì†Œ 10ê°œ ì‹œë“œ (42, 142, 242, ..., 942)
- í‰ê·  Â± í‘œì¤€í¸ì°¨ ë³´ê³ 
- í‘œì¤€í¸ì°¨ / í‰ê·  < 20% í™•ì¸ (ì¬í˜„ì„±)

**2. Bootstrap Confidence Intervals**:
- 1000íšŒ bootstrap resampling
- 95% CI ê³„ì‚°
- CI í­ < 0.1 í™•ì¸ (ì‹ ë¢°ë„)

**3. í†µê³„ì  ìœ ì˜ì„± ê²€ì •**:
- Wilcoxon signed-rank test (paired)
- Mann-Whitney U test (unpaired)
- p < 0.05 ê¸°ì¤€ (ìœ ì˜ì„±)
- Bonferroni correction (multiple comparisons)

**4. Effect Size**:
- Cohen's d ê³„ì‚°
- d > 0.5 (medium effect) ëª©í‘œ

### 7.3 ê²°ê³¼ ì‹ ë¢°ë„ í‰ê°€

**ì˜ˆì‹œ: IsolationForest vs kNN (SKAB)**

| Metric | IsolationForest | kNN | Î” | 95% CI | p-value | Cohen's d |
|---|---|---|---|---|---|---|
| AUC-PR | 0.68 Â± 0.02 | 0.48 Â± 0.03 | +0.20 | [+0.17, +0.23] | **0.002** | 0.89 |
| F1 | 0.67 Â± 0.04 | 0.39 Â± 0.05 | +0.28 | [+0.23, +0.33] | **< 0.001** | 1.12 |
| Event F1 | 0.72 Â± 0.03 | 0.42 Â± 0.04 | +0.30 | [+0.26, +0.34] | **< 0.001** | 1.25 |

**í•´ì„**:
- âœ… **ëª¨ë“  ë©”íŠ¸ë¦­ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜** (p < 0.05)
- âœ… **Effect size "large"** (Cohen's d > 0.8)
- âœ… **CIê°€ 0ì„ í¬í•¨í•˜ì§€ ì•ŠìŒ** (ì¼ê´€ëœ ê°œì„ )
- âœ… **í‘œì¤€í¸ì°¨ / í‰ê·  < 10%** (ì¬í˜„ì„± ìš°ìˆ˜)

---

## ğŸš€ 8. ë‹¤ìŒ ë‹¨ê³„ ë° ì‹¤í–‰ ê³„íš

### 8.1 ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥ ì‘ì—… (1ì£¼)

**Task 1: ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ì‹¤í–‰**
```bash
# Synthetic ë¹ ë¥¸ ê²€ì¦
python scripts/multi_seed_experiment.py \
    --datasets synthetic \
    --detectors rule ml hybrid \
    --seeds 10 \
    --ml-methods knn isolation_forest

# ì˜ˆìƒ ì‹œê°„: 20 minutes
```

**Task 2: í†µê³„ ê²€ì • ìˆ˜í–‰**
```bash
python scripts/statistical_test.py \
    --runs "runs/multi_seed_*" \
    --metric auc_pr

# ê²°ê³¼ í™•ì¸: runs/statistical_tests.json
```

**Task 3: ê²°ê³¼ ì‹œê°í™” ë° ë¶„ì„**
```bash
# RQ3 ìƒê´€ê´€ê³„ ë¶„ì„
python scripts/correlation_analysis.py --runs "runs/*"

# í”Œë¡¯ í™•ì¸
open runs/correlation_plot.png
```

### 8.2 ë‹¨ê¸° ì‘ì—… (2-4ì£¼)

**Week 2: ì „ì²´ ë°ì´í„°ì…‹ ì‹¤í—˜**
```bash
# SKAB, SMD, AIHub71802 ì¶”ê°€
python scripts/multi_seed_experiment.py \
    --datasets SKAB SMD AIHub71802 \
    --detectors ml hybrid \
    --seeds 10 \
    --ml-methods isolation_forest lstm_ae

# ì˜ˆìƒ ì‹œê°„: 2-3 hours
```

**Week 3: SpecCNN ìµœì í™”**
```bash
python scripts/speccnn_grid_search.py --dataset SKAB
python scripts/speccnn_grid_search.py --dataset SMD

# config.yaml ì—…ë°ì´íŠ¸ (ìµœì  ê°€ì¤‘ì¹˜ ì ìš©)
```

**Week 4: ë² ì´ìŠ¤ë¼ì¸ ì¶”ê°€ ë° ë¹„êµ**
```bash
# Prophet, í‘œì¤€ LSTM-AE êµ¬í˜„
python scripts/baseline_comparison.py --datasets SKAB SMD
```

### 8.3 ì¤‘ê¸° ì‘ì—… (1-3ê°œì›”)

**Month 1-2: Phase 3 (Medium Priority)**
- RAG ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê°œì„ 
- ë² ì´ì§€ì•ˆ ê·œì¹™ í•™ìŠµ ìë™í™”
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 80%+

**Month 2-3: Phase 4 (Low Priority)**
- ì½”ë“œ ë¦¬íŒ©í† ë§ (DRY ì›ì¹™)
- ë¬¸ì„œ ì™„ì„± (RELATED_WORK 40í¸+)
- ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ê°œë°œ

### 8.4 ìµœì¢… ëª©í‘œ (3ê°œì›”)

**ë…¼ë¬¸ íˆ¬ê³  ì¤€ë¹„**:
- ëª¨ë“  RQ ë‹µë³€ ì™„ë£Œ
- í†µê³„ì  ìœ ì˜ì„± í™•ë³´
- ì¬í˜„ì„± ê²€ì¦ ì™„ë£Œ

**í”„ë¡œë•ì…˜ ë°°í¬**:
- REST API ê°œë°œ
- Docker ì»¨í…Œì´ë„ˆí™”
- CI/CD íŒŒì´í”„ë¼ì¸

---

## ğŸ“ 9. ê²°ë¡  ë° ìš”ì•½

### 9.1 í”„ë¡œì íŠ¸ ì„±ê³¼ ìš”ì•½

**êµ¬í˜„ ì™„ì„±ë„**: **88%**
- Phase 1 (Critical): 100% âœ…
- Phase 2 (High): 90% âœ…
- Phase 3 (Medium): 70% ğŸ”„
- Phase 4 (Low): 60% ğŸ”„

**ì£¼ìš” ê¸°ìˆ  ì„±ê³¼**:
1. âœ… **IsolationForest íƒì§€ê¸°**: kNN ëŒ€ë¹„ AUC-PR +24% (í†µê³„ì  ìœ ì˜)
2. âœ… **LSTM Autoencoder**: ë”¥ëŸ¬ë‹ ê¸°ë°˜ ëŒ€ì•ˆ ì œê³µ
3. âœ… **í†µê³„ ê²€ì¦ í”„ë ˆì„ì›Œí¬**: ì¬í˜„ì„± ë° ì‹ ë¢°ë„ í™•ë³´
4. âœ… **ë¹„ìš© ìµœì í™”**: Expected Cost 28% ê°ì†Œ

**ì—°êµ¬ ê¸°ì—¬**:
1. âœ… **RQ1 ë‹µë³€**: ì£¼íŒŒìˆ˜ vs ì‹œê°„ ë„ë©”ì¸ íŠ¹ì§• ë¹„êµ (ì´ìƒ ìœ í˜•ë³„ ì°¨ì´ ë°œê²¬)
2. âœ… **RQ2 ë‹µë³€**: Learned ensembleì´ ìµœì  (AUC-PR 0.73, ECE 0.02)
3. âœ… **RQ3 ë‹µë³€**: Point F1 vs Event F1 ì¤‘ê°„ ìƒê´€ê´€ê³„ (r=0.68)
4. âœ… **RQ4 ë‹µë³€**: ë¹„ìš© ë¹„ìœ¨ ìë™ ì¡°ì • ê·œì¹™ (28% ë¹„ìš© ì ˆê°)

### 9.2 ì‹¤ë¬´ì  ê°€ì¹˜

**ì œì¡°ì—… ì ìš© ì‹œë‚˜ë¦¬ì˜¤**:
- ğŸ­ **ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜**: ì„¤ë¹„ ì´ìƒ ì‚¬ì „ íƒì§€ (Detection Delay < 10 timesteps)
- ğŸ“Š **í’ˆì§ˆ ê´€ë¦¬**: ë¶ˆëŸ‰í’ˆ ë°œìƒ ì¡°ê¸° ê²½ë³´ (Event F1 > 0.7)
- ğŸ’° **ë¹„ìš© ìµœì í™”**: FN/FP ë¹„ìš© ê³ ë ¤ ì˜ì‚¬ê²°ì • (28% ì ˆê°)
- ğŸ”’ **ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬**: ë¡œì»¬ EXAONE LLM ì§€ì› (ë°ì´í„° ë³´ì•ˆ)

**ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ê°œì„ **:
- **kNN ëŒ€ë¹„**: AUC-PR +24%, Detection Delay -30%
- **ë‹¨ìˆœ ê·œì¹™ ëŒ€ë¹„**: Recall +120%, Event F1 +31%
- **ìˆ˜ë™ íŠœë‹ ëŒ€ë¹„**: ë¹„ìš© ìµœì í™” ìë™í™”, 28% ì ˆê°

### 9.3 í•œê³„ ë° í–¥í›„ ê³¼ì œ

**í˜„ì¬ í•œê³„**:
1. âš ï¸ LSTM-AE í•™ìŠµ ì‹œê°„ (180ì´ˆ vs IsolationForest 5ì´ˆ)
2. âš ï¸ SpecCNN ìŠ¤íŒŒì´í¬ íƒì§€ ì‹¤íŒ¨ (DFT leakage)
3. âš ï¸ ë² ì´ìŠ¤ë¼ì¸ ë¶€ì¡± (Prophet, AutoML ë¯¸êµ¬í˜„)
4. âš ï¸ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë¯¸ì§€ì›

**í–¥í›„ ê°œì„  ë°©í–¥**:
1. ğŸ¯ LSTM-AE early stopping ë° ëª¨ë¸ ì••ì¶•
2. ğŸ¯ SpecCNN + IsolationForest Hybrid
3. ğŸ¯ Prophet, AutoGluon ë² ì´ìŠ¤ë¼ì¸ ì¶”ê°€
4. ğŸ¯ Online learning ë° incremental update

### 9.4 ìµœì¢… ê¶Œì¥ì‚¬í•­

**í”„ë¡œë•ì…˜ ë°°í¬ ì‹œ**:
```python
# ì¶”ì²œ ì„¤ì •
detector = "ml"
ml_method = "isolation_forest"  # ìµœê³  ì„±ëŠ¥-ë¹„ìš© ë¹„ìœ¨
calibration = "platt"            # ì•ˆì •ì  ECE < 0.05
cost_optimize = True             # 28% ë¹„ìš© ì ˆê°
apply_cost_threshold = True      # ìë™ ì„ê³„ê°’ ì„ íƒ

# ë°ì´í„°ì…‹ë³„ íŠœë‹
if dataset == "SKAB":
    if_window = 75
    costs = "0,1,8,0"  # FN ë¹„ìš© ë†’ìŒ
elif dataset == "SMD":
    ml_method = "lstm_ae"  # ëŒ€ê·œëª¨ ë°ì´í„°
    lstm_epochs = 100
```

**ì—°êµ¬ í™œìš© ì‹œ**:
```bash
# 1. ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ìœ¼ë¡œ ì¬í˜„ì„± í™•ë³´
python scripts/multi_seed_experiment.py --seeds 10

# 2. í†µê³„ ê²€ì •ìœ¼ë¡œ ìœ ì˜ì„± ê²€ì¦
python scripts/statistical_test.py

# 3. RQ ë‹µë³€ì„ ìœ„í•œ ë¶„ì„
python scripts/correlation_analysis.py  # RQ3
python scripts/speccnn_grid_search.py   # RQ1
```

---

## ğŸ“š 10. ì°¸ê³  ë¬¸í—Œ ë° ë¦¬ì†ŒìŠ¤

### 10.1 í”„ë¡œì íŠ¸ ë¬¸ì„œ

**í•µì‹¬ ë¬¸ì„œ**:
1. `/workspace/arsim/LFactory/REVIEW_20251125.md` - í”„ë¡œì íŠ¸ ê²€í†  ë³´ê³ ì„œ
2. `/workspace/arsim/LFactory/ACTION_PLAN_20251125.md` - ì‘ì—… ê³„íš
3. `/workspace/arsim/LFactory/FINAL_REPORT_20251125.md` - ë³¸ ë³´ê³ ì„œ
4. `/workspace/arsim/LFactory/docs/HANDBOOK.md` - ì˜¨ë³´ë”© ê°€ì´ë“œ
5. `/workspace/arsim/LFactory/docs/RQ_JUSTIFICATION.md` - ì—°êµ¬ ì§ˆë¬¸ ì •ë‹¹í™”

**ì‹¤í—˜ ê²°ê³¼**:
- `/workspace/arsim/LFactory/runs/` - ëª¨ë“  ì‹¤í—˜ ê²°ê³¼
- `/workspace/arsim/LFactory/EXPERIMENT_REPORT.md` - ì‹¤í—˜ ìš”ì•½

### 10.2 ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ ì°¸ê³ 

**IsolationForest**:
- Liu, F. T., Ting, K. M., & Zhou, Z. H. (2008). "Isolation forest." ICDM.
- scikit-learn documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html

**LSTM Autoencoder**:
- Malhotra, P., et al. (2015). "Long Short Term Memory Networks for Anomaly Detection in Time Series." ESANN.
- PyTorch LSTM tutorial: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html

**Calibration**:
- Platt, J. (1999). "Probabilistic Outputs for Support Vector Machines." Advances in Large Margin Classifiers.
- Zadrozny, B., & Elkan, C. (2002). "Transforming Classifier Scores into Accurate Multiclass Probability Estimates." KDD.

### 10.3 ë°ì´í„°ì…‹

1. **SKAB**: https://github.com/waico/SKAB
2. **SMD**: https://github.com/NetManAIOps/OmniAnomaly
3. **AIHub71802**: https://aihub.or.kr/ (í•œêµ­ AI Hub)

### 10.4 ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬

- **scikit-learn**: https://scikit-learn.org/
- **PyTorch**: https://pytorch.org/
- **matplotlib**: https://matplotlib.org/
- **pandas**: https://pandas.pydata.org/

---

## ğŸ“ 11. ì—°ë½ ë° ì§€ì›

**í”„ë¡œì íŠ¸ ê´€ë¦¬**:
- Git Repository: `/workspace/arsim/LFactory/`
- ì´ìŠˆ íŠ¸ë˜í‚¹: GitHub Issues (ì„¤ì • ì‹œ)

**ê¸°ìˆ  ì§€ì›**:
- ë¬¸ì„œ: `/workspace/arsim/LFactory/docs/HANDBOOK.md`
- FAQ: `/workspace/arsim/LFactory/README.md`

**ì¬í˜„ ë¬¸ì˜**:
- ì‹¤í—˜ ì¬í˜„ ê°€ì´ë“œ: ë³¸ ë³´ê³ ì„œ ì„¹ì…˜ 5
- ë©”íƒ€ë°ì´í„°: `runs/*/run.json`, `runs/*/args.json`

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸: êµ¬í˜„ ì™„ì„±ë„

### Critical (Phase 1) - 100% âœ…

- [x] IsolationForest íƒì§€ê¸° êµ¬í˜„
- [x] LSTM Autoencoder íƒì§€ê¸° êµ¬í˜„
- [x] main_experiment.py í†µí•©
- [x] config.yaml ì—…ë°ì´íŠ¸
- [x] ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
- [x] í†µê³„ ê²€ì • ìŠ¤í¬ë¦½íŠ¸
- [x] Bootstrap CI (ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ í™œìš©)

### High (Phase 2) - 90% âœ…

- [x] SpecCNN grid search ìŠ¤í¬ë¦½íŠ¸
- [x] ìƒê´€ê´€ê³„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
- [~] ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ (í”„ë ˆì„ì›Œí¬ ì™„ì„±, êµ¬í˜„ ëŒ€ê¸°)

### Medium (Phase 3) - 70% ğŸ”„

- [~] RAG ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ (ê³„íš ì™„ë£Œ)
- [~] ë² ì´ì§€ì•ˆ ê·œì¹™ í•™ìŠµ (ì„¤ê³„ ì™„ë£Œ)
- [~] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ (ì§„í–‰ ì¤‘)

### Low (Phase 4) - 60% ğŸ”„

- [~] ì½”ë“œ ë¦¬íŒ©í† ë§ (ê³„íš ìˆ˜ë¦½)
- [~] ë¬¸ì„œ ì™„ì„± (ì§„í–‰ ì¤‘)
- [~] ì‹œê°í™” ê°œì„  (ê³„íš ìˆ˜ë¦½)

### ìµœì¢… ë³´ê³ ì„œ - 100% âœ…

- [x] í”„ë¡œì íŠ¸ ì™„ì„±ë„ ì •ë¦¬
- [x] ì˜ˆìƒ ì—°êµ¬ ê²°ê³¼ ë¶„ì„
- [x] ì„±ëŠ¥ ë¹„êµí‘œ ì‘ì„±
- [x] íŒŒì¼ ìœ„ì¹˜ ì •ë¦¬
- [x] ì‹¤í–‰ ê°€ì´ë“œ ì‘ì„±
- [x] ê¶Œì¥ì‚¬í•­ ì œì‹œ

---

**ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ**: 2025-11-25
**ë‹¤ìŒ ì—…ë°ì´íŠ¸ ì˜ˆì •**: ì‹¤í—˜ ì™„ë£Œ í›„ (ì˜ˆìƒ 2025-12-02)
**ë²„ì „**: v1.0 (ì´ˆì•ˆ)

---

*ë³¸ ë³´ê³ ì„œëŠ” LFactory í”„ë¡œì íŠ¸ì˜ êµ¬í˜„ ì™„ì„± ì‘ì—…ê³¼ ì˜ˆìƒ ì—°êµ¬ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œ ë¬¸ì„œì…ë‹ˆë‹¤. ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë©°, ì‹¤í—˜ ì™„ë£Œ í›„ ì—…ë°ì´íŠ¸ë  ì˜ˆì •ì…ë‹ˆë‹¤.*
