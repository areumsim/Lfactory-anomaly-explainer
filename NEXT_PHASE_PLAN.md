# LFactory ë‹¤ìŒ ë‹¨ê³„ ì¢…í•© ê³„íšì„œ
## Next Phase Comprehensive Plan

**ì‘ì„±ì¼**: 2025-11-24
**í˜„ì¬ ìƒíƒœ**: Phase 1 (Detect) 100% ì™„ë£Œ
**ëª©í‘œ**: Phase 1 ê³ ë„í™” + Phase 2 (Explain) ì™„ì „ êµ¬í˜„

---

# ğŸ“Š í˜„ì¬ ì™„ë£Œ ìƒíƒœ

## âœ… Phase 1: Detect (100% ì™„ë£Œ)

### ì™„ë£Œëœ ì‘ì—…
- [x] 6ê°€ì§€ detector êµ¬í˜„ (Rule, kNN, IF, LSTM-AE, Hybrid, SpecCNN)
- [x] 480 runs ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ (96% ì„±ê³µë¥ )
- [x] í†µê³„ì  ê²€ì¦ (Wilcoxon, Bootstrap CI)
- [x] ìƒê´€ê´€ê³„ ë¶„ì„ (Point-wise vs Event-wise)
- [x] ì¢…í•© ì‹¤í—˜ ë³´ê³ ì„œ (35í˜ì´ì§€)
- [x] Calibration (Platt, Isotonic, Temperature)
- [x] Cost-sensitive threshold optimization

### ë°œê²¬ëœ ê°œì„  ì˜ì—­
- [ ] SpecCNN weight ìµœì í™” (í˜„ì¬ AUC-PR=0)
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ì²´ grid search
- [ ] ë‹¤ì¤‘ íŒŒì¼ í‰ê°€ (SKAB 30ê°œ íŒŒì¼)
- [ ] AIHub71802 ë°ì´í„° ë¬¸ì œ í•´ê²°
- [ ] ì‹¤ì‹œê°„ ë°°í¬ ì‹œìŠ¤í…œ êµ¬ì¶•

---

# ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ ì „ì²´ ë¡œë“œë§µ

## Phase 1.5: Detect ê³ ë„í™” (2-3ì£¼)

### Week 1: ë¹„êµ ë¶„ì„ ë° ì‹œê°í™”
- [ ] ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë³´ê³ ì„œ ì‘ì„±
- [ ] ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ìƒì„±
- [ ] ë…¼ë¬¸ ì œì¶œìš© figure ìƒì„±

### Week 2: ìµœì í™” ë° ê²€ì¦
- [ ] SpecCNN weight grid search
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ì²´ ìµœì í™”
- [ ] ë‹¤ì¤‘ íŒŒì¼ SKAB í‰ê°€

### Week 3: ì‹¤ë¬´ ì ìš©
- [ ] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í”„ë¡œí† íƒ€ì…
- [ ] ë°°í¬ ê°€ì´ë“œ ì‘ì„±
- [ ] ì‚¬ìš©ì ë§¤ë‰´ì–¼ ì‘ì„±

## Phase 2: Explain (3-4ì£¼)

### Week 1: LLM í†µí•©
- [ ] OpenAI API ë˜ëŠ” Local EXAONE ì„¤ì •
- [ ] RAG (Retrieval-Augmented Generation) êµ¬í˜„
- [ ] Prompt engineering

### Week 2: ì„¤ëª… ìƒì„±
- [ ] Anomaly ì„¤ëª… í…œí”Œë¦¿ ì‘ì„±
- [ ] ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•
- [ ] ì„¤ëª… í’ˆì§ˆ í‰ê°€

### Week 3: Bayesian Prior
- [ ] Cost matrix ë™ì  ì¡°ì •
- [ ] ì‚¬ìš©ì í”¼ë“œë°± í•™ìŠµ
- [ ] A/B í…ŒìŠ¤íŠ¸

### Week 4: í†µí•© ë° ê²€ì¦
- [ ] End-to-end íŒŒì´í”„ë¼ì¸ í†µí•©
- [ ] ì‚¬ìš©ì í…ŒìŠ¤íŠ¸
- [ ] ìµœì¢… ë³´ê³ ì„œ

---

# ğŸ“‹ Stage 7-12 ìƒì„¸ ê³„íš

---

## Stage 7: ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë³´ê³ ì„œ ì‘ì„± (2-3ì¼)

### ëª©í‘œ
ì‹¤í—˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ **í•™ìˆ  ë…¼ë¬¸ê¸‰ ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ** ì‘ì„±

### ì‘ì—… ë‚´ì—­

#### 7.1 ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” ìƒì„±
**ì¶œë ¥ë¬¼**: `figures/` ë””ë ‰í† ë¦¬ì— publication-quality figures

1. **ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸**
   - Grouped bar chart: F1, AUC-PR by detector
   - Box plot: Performance distribution across seeds
   - Radar chart: Multi-metric comparison (F1, AUC-PR, Precision, Recall, ECE)

2. **í†µê³„ì  ìœ ì˜ì„± íˆíŠ¸ë§µ**
   - Wilcoxon p-value heatmap (6Ã—6 detector pairs)
   - ìƒ‰ìƒ ì½”ë“œ: p<0.001 (dark green), p<0.05 (light green), pâ‰¥0.05 (red)

3. **ì‹ ë¢°êµ¬ê°„ ë¹„êµ**
   - Error bar plot: Mean Â± 95% CI for each detector
   - Datasetë³„ subplot (SKAB, SMD, Synthetic)

4. **ROC/PR ê³¡ì„  ë¹„êµ**
   - Overlay all 6 detectors on same plot
   - Datasetë³„ subplot

5. **Calibration ë¹„êµ**
   - Reliability diagram (predicted prob vs actual freq)
   - 6 detectors Ã— 3 datasets = 18 subplots

6. **Event-wise ì„±ëŠ¥ ë¶„ì„**
   - Detection delay distribution (box plot)
   - Lead time vs F1 scatter plot
   - Event recall vs Point recall correlation

7. **Cost-sensitive ë¶„ì„**
   - Cost reduction by detector (bar chart)
   - Optimal threshold distribution (histogram)

**êµ¬í˜„ ë°©ë²•**:
```python
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Load results
df = pd.read_csv("runs/all_results.csv")

# Figure 1: Performance comparison
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, dataset in enumerate(["SKAB", "SMD", "synthetic"]):
    data = df[df["dataset"] == dataset]
    data.groupby("detector")["auc_pr"].mean().plot(kind="bar", ax=axes[i])
    axes[i].set_title(f"{dataset} - AUC-PR by Detector")
plt.savefig("figures/performance_comparison.png", dpi=300)
```

#### 7.2 ë°ì´í„°ì…‹ë³„ ìƒì„¸ ë¶„ì„
**ì¶œë ¥ë¬¼**: `ALGORITHM_COMPARISON_REPORT.md`

ê° ë°ì´í„°ì…‹ë³„ë¡œ:
1. **Winner ì„ ì • ë° ê·¼ê±°**
   - Best F1, Best AUC-PR, Best stability (ë‚®ì€ std)
   - í†µê³„ì  ìœ ì˜ì„± í™•ì¸

2. **ì•Œê³ ë¦¬ì¦˜ íŠ¹ì„± ë¶„ì„**
   - ì™œ íŠ¹ì • ì•Œê³ ë¦¬ì¦˜ì´ ì˜ ì‘ë™í–ˆëŠ”ê°€?
   - ë°ì´í„°ì…‹ íŠ¹ì„±ê³¼ì˜ ê´€ê³„

3. **ì‹¤ë¬´ ê¶Œì¥ì‚¬í•­**
   - ì´ ë°ì´í„°ì…‹ê³¼ ìœ ì‚¬í•œ ê²½ìš° ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜?
   - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ê°€ì´ë“œ

#### 7.3 í¬ë¡œìŠ¤ ë°ì´í„°ì…‹ ì¼ë°˜í™” ë¶„ì„

**ì§ˆë¬¸**:
- ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ ìš°ìˆ˜í•œ ì•Œê³ ë¦¬ì¦˜ì´ ìˆëŠ”ê°€?
- ë°ì´í„°ì…‹ íŠ¹ì„±ì— ë”°ë¼ ì•Œê³ ë¦¬ì¦˜ ì„ íƒì´ ë‹¬ë¼ì§€ëŠ”ê°€?

**ë¶„ì„**:
1. **Ranking consistency**
   - Kendall's Tau correlation between dataset rankings
   - Example: SKABì—ì„œ 1ë“±ì¸ LSTM-AEê°€ SMDì—ì„œë„ top-3ì— ë“œëŠ”ê°€?

2. **ë°ì´í„°ì…‹ íŠ¹ì„± vs ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥**
   - Anomaly rate vs ìµœì  ì•Œê³ ë¦¬ì¦˜
   - Series length vs ìµœì  ì•Œê³ ë¦¬ì¦˜
   - Number of features vs ìµœì  ì•Œê³ ë¦¬ì¦˜

3. **Meta-learning ê°€ëŠ¥ì„±**
   - ë°ì´í„°ì…‹ íŠ¹ì„±ë§Œìœ¼ë¡œ ìµœì  ì•Œê³ ë¦¬ì¦˜ ì˜ˆì¸¡ ê°€ëŠ¥?

#### 7.4 Ablation Study í™•ì¥

**í˜„ì¬**: SKABì—ì„œë§Œ ê¸°ë³¸ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸
**ëª©í‘œ**: ì „ì²´ grid search ìˆ˜í–‰

**Grid Search ì„¤ê³„**:
```python
# Full factorial design
hyperparameters = {
    "Rule": {
        "z_window": [30, 50, 80, 100],
        "threshold": [2.5, 3.0, 3.5],
        "robust": [True, False]
    },
    "kNN": {
        "k": [5, 10, 15, 20],
        "quantile": [0.95, 0.97, 0.99]
    },
    "IsolationForest": {
        "window": [30, 50, 80],
        "contamination": [0.05, 0.1, 0.15],
        "n_estimators": [50, 100, 200]
    },
    "LSTM-AE": {
        "seq_len": [30, 50, 80],
        "latent_dim": [16, 32, 64],
        "epochs": [30, 50],
        "lr": [0.0005, 0.001, 0.002]
    },
    "Hybrid": {
        "alpha": [0.3, 0.5, 0.7, 0.9],
        "rule_window": [30, 50, 80],
        "ml_k": [5, 10, 20]
    }
}
```

**Total combinations**:
- Rule: 4Ã—3Ã—2 = 24
- kNN: 4Ã—3 = 12
- IsolationForest: 3Ã—3Ã—3 = 27
- LSTM-AE: 3Ã—3Ã—2Ã—3 = 54 (expensive!)
- Hybrid: 4Ã—3Ã—3 = 36
- **Total**: 153 runs per dataset

**Optimization**:
- Random search: 20% of full grid (30 runs per detector)
- Bayesian optimization: TPE (Tree-structured Parzen Estimator)

#### 7.5 ë…¼ë¬¸ ì‘ì„±

**ëª©í‘œ**: êµ­ì œ í•™ìˆ ì§€ íˆ¬ê³  ìˆ˜ì¤€ ë…¼ë¬¸

**êµ¬ì¡°**:
1. **Title**: "Comprehensive Evaluation of Time Series Anomaly Detection: A Multi-Algorithm, Multi-Dataset Study with Statistical Validation"

2. **Abstract** (250 words)
   - Context, gap, method, results, conclusion

3. **Introduction**
   - Problem statement
   - Research questions (RQ1-4)
   - Contributions

4. **Related Work**
   - Rule-based methods
   - ML methods
   - Deep learning methods
   - Comparison studies

5. **Methodology**
   - Datasets (4)
   - Algorithms (6)
   - Evaluation protocol (multi-seed, metrics)
   - Statistical validation

6. **Results**
   - Performance comparison (Table + Figure)
   - Statistical tests (Wilcoxon, Bootstrap CI)
   - Correlation analysis

7. **Discussion**
   - RQ answers
   - Algorithm selection guide
   - Limitations

8. **Conclusion**
   - Summary
   - Future work

**Target Journals**:
- IEEE Transactions on Knowledge and Data Engineering (TKDE)
- ACM Transactions on Knowledge Discovery from Data (TKDD)
- Data Mining and Knowledge Discovery (DMKD)

**ì˜ˆìƒ ì‘ì—… ì‹œê°„**: 3-5ì¼

---

## Stage 8: SpecCNN Weight ìµœì í™” (1-2ì¼)

### ëª©í‘œ
SpecCNNì˜ AUC-PR=0 ë¬¸ì œ í•´ê²° â†’ ì‹¤ìš©ì ì¸ frequency-domain detectorë¡œ ê°œì„ 

### 8.1 Grid Search êµ¬í˜„

**í˜„ì¬ ë¬¸ì œ**:
- Heuristic weights: w_low=-0.2, w_mid=0.6, w_high=0.6
- ê²°ê³¼: F1ì€ ë†’ì§€ë§Œ AUC-PR=0 (ranking ì™„ì „ ì‹¤íŒ¨)

**í•´ê²° ë°©ë²•**: Grid searchë¡œ ìµœì  weights ì°¾ê¸°

**êµ¬í˜„**:
```python
# scripts/speccnn_grid_search.py ê°œì„ 

import itertools
import json
from pathlib import Path

def grid_search_speccnn_weights(dataset="SKAB", data_root=""):
    """Grid search for optimal SpecCNN frequency band weights."""

    # Define search space
    w_low_range = [-1.0, -0.5, -0.2, 0.0, 0.2, 0.5]
    w_mid_range = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
    w_high_range = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]

    best_auc_pr = 0.0
    best_weights = None
    results = []

    total_combinations = len(w_low_range) * len(w_mid_range) * len(w_high_range)
    print(f"Total combinations: {total_combinations}")

    for i, (w_l, w_m, w_h) in enumerate(itertools.product(w_low_range, w_mid_range, w_high_range)):
        print(f"[{i+1}/{total_combinations}] Testing: w_low={w_l}, w_mid={w_m}, w_high={w_h}")

        # Run SpecCNN with these weights
        cmd = [
            "python3", "-m", "experiments.main_experiment",
            "--dataset", dataset,
            "--detector", "speccnn",
            "--seed", "42",
            "--sc-weights", str(w_l), str(w_m), str(w_h),
            "--run-id", f"speccnn_grid_{i}",
            "--out-json", f"runs/speccnn_grid_{i}.json"
        ]

        if dataset != "synthetic":
            cmd.extend(["--data-root", data_root])

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            # Load result
            with open(f"runs/speccnn_grid_{i}.json") as f:
                data = json.load(f)
                auc_pr = data["metrics"]["auc_pr"]
                f1 = data["metrics"]["f1"]

                results.append({
                    "w_low": w_l,
                    "w_mid": w_m,
                    "w_high": w_h,
                    "auc_pr": auc_pr,
                    "f1": f1,
                })

                if auc_pr > best_auc_pr:
                    best_auc_pr = auc_pr
                    best_weights = (w_l, w_m, w_h)
                    print(f"  âœ¨ New best! AUC-PR={auc_pr:.4f}, F1={f1:.4f}")
        else:
            print(f"  âŒ Failed")

    # Save results
    output = {
        "dataset": dataset,
        "best_weights": {"low": best_weights[0], "mid": best_weights[1], "high": best_weights[2]},
        "best_auc_pr": best_auc_pr,
        "all_results": results
    }

    with open(f"runs/speccnn_grid_search_{dataset}.json", "w") as f:
        json.dump(output, f, indent=2)

    print(f"\nâœ… Grid search complete!")
    print(f"ğŸ“Š Best weights: low={best_weights[0]}, mid={best_weights[1]}, high={best_weights[2]}")
    print(f"ğŸ“ˆ Best AUC-PR: {best_auc_pr:.4f}")

    return best_weights, best_auc_pr
```

**ì‹¤í–‰**:
```bash
python3 scripts/speccnn_grid_search.py --dataset SKAB --data-root /workspace/data1/arsim/LFactory_d
python3 scripts/speccnn_grid_search.py --dataset SMD --data-root /workspace/data1/arsim/LFactory_d
python3 scripts/speccnn_grid_search.py --dataset synthetic
```

**ì˜ˆìƒ ì‹œê°„**: 6Ã—6Ã—6 = 216 combinations Ã— 5ì´ˆ = 18ë¶„ per dataset

### 8.2 ìµœì  Weightsë¡œ ì¬ì‹¤í—˜

ìµœì  weights ë°œê²¬ í›„:
1. 20-seed ì¬ì‹¤í—˜
2. ì„±ëŠ¥ ë¹„êµ: Before (AUC-PR=0) vs After
3. COMPREHENSIVE_REPORT ì—…ë°ì´íŠ¸

### 8.3 Frequency-Domain ë¶„ì„

**ì¶”ê°€ ë¶„ì„**:
1. **Anomalyì˜ ì£¼íŒŒìˆ˜ íŠ¹ì„±**
   - Normal vs Anomalyì˜ STFT ì°¨ì´ ì‹œê°í™”
   - ì–´ë–¤ ì£¼íŒŒìˆ˜ ëŒ€ì—­ì´ anomalyë¥¼ ê°€ì¥ ì˜ êµ¬ë¶„í•˜ëŠ”ê°€?

2. **Adaptive Band Selection**
   - ë°ì´í„°ì…‹ë§ˆë‹¤ ë‹¤ë¥¸ band ì‚¬ìš©
   - í•™ìŠµ ê¸°ë°˜ band weight ì„ íƒ

3. **SpecCNN vs LSTM-AE ë¹„êµ**
   - Frequency domain vs Time domain
   - ì–¸ì œ SpecCNNì´ ìœ ë¦¬í•œê°€?

---

## Stage 9: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ì²´ ìµœì í™” (3-5ì¼)

### ëª©í‘œ
ê° detectorì˜ ìµœì  hyperparameter ë°œê²¬ â†’ ì„±ëŠ¥ ìƒí•œì„  ì¸¡ì •

### 9.1 Bayesian Optimization êµ¬í˜„

**Random Searchë³´ë‹¤ íš¨ìœ¨ì **:
- ì´ì „ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ìŒ ì‹œë„ ê²°ì •
- ì „ì²´ gridì˜ 10-20%ë§Œ íƒìƒ‰ìœ¼ë¡œ ìµœì ê°’ ê·¼ì‚¬

**êµ¬í˜„**:
```python
# scripts/bayesian_optimization.py

from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern
import numpy as np

def bayesian_optimize(detector, dataset, n_iterations=30):
    """Bayesian optimization for hyperparameter tuning."""

    # Define search space
    if detector == "isolation_forest":
        space = {
            "window": (20, 100, "int"),
            "contamination": (0.01, 0.2, "float"),
            "n_estimators": (50, 200, "int")
        }
    elif detector == "lstm_ae":
        space = {
            "seq_len": (20, 100, "int"),
            "latent_dim": (8, 64, "int"),
            "lr": (0.0001, 0.01, "float")
        }
    # ... other detectors

    # Gaussian Process model
    gp = GaussianProcessRegressor(
        kernel=Matern(nu=2.5),
        n_restarts_optimizer=10
    )

    X_observed = []
    y_observed = []

    for i in range(n_iterations):
        # Acquisition function: Expected Improvement
        if i < 5:
            # Random exploration for first 5 iterations
            params = sample_random(space)
        else:
            # Bayesian optimization
            params = acquisition_function(gp, space, X_observed, y_observed)

        # Run experiment
        auc_pr = run_experiment(detector, dataset, params)

        # Update observations
        X_observed.append(params)
        y_observed.append(auc_pr)

        # Fit GP
        gp.fit(X_observed, y_observed)

        print(f"[{i+1}/{n_iterations}] Params={params}, AUC-PR={auc_pr:.4f}")

    # Return best
    best_idx = np.argmax(y_observed)
    return X_observed[best_idx], y_observed[best_idx]
```

### 9.2 ë°ì´í„°ì…‹ë³„ ìµœì  ì„¤ì • ë„ì¶œ

**ì¶œë ¥ë¬¼**: `HYPERPARAMETER_GUIDE.md`

ê° detector Ã— dataset ì¡°í•©ì˜ ìµœì  ì„¤ì •:
```markdown
## IsolationForest on SKAB
- window: 65
- contamination: 0.08
- n_estimators: 120
- **Performance**: AUC-PR=0.28 (vs 0.24 baseline)
- **Improvement**: +16.7%

## LSTM-AE on SMD
- seq_len: 80
- latent_dim: 48
- lr: 0.0008
- epochs: 45
- **Performance**: F1=0.52 (vs 0.46 baseline)
- **Improvement**: +13%
```

### 9.3 ìµœì  ì„¤ì •ìœ¼ë¡œ ì¬ì‹¤í—˜

1. ìµœì  hyperparameterë¡œ 20-seed ì¬ì‹¤í—˜
2. Baseline (default params) vs Optimized ë¹„êµ
3. ì„±ëŠ¥ ê°œì„ ë¥  ì¸¡ì •

**ì˜ˆìƒ ê²°ê³¼**:
- IsolationForest: +10-20% ê°œì„ 
- LSTM-AE: +5-15% ê°œì„ 
- kNN: +5-10% ê°œì„ 

---

## Stage 10: ë‹¤ì¤‘ íŒŒì¼ SKAB í‰ê°€ (2-3ì¼)

### ëª©í‘œ
SKAB ì „ì²´ 30ê°œ íŒŒì¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦

### 10.1 SKAB ì „ì²´ íŒŒì¼ ì‹¤í—˜

**í˜„ì¬**: valve1/0.csv 1ê°œ íŒŒì¼ë§Œ ì‚¬ìš©
**ëª©í‘œ**: ì „ì²´ íŒŒì¼ë¡œ í‰ê°€

**SKAB êµ¬ì¡°**:
```
SKAB/
â”œâ”€â”€ valve1/
â”‚   â”œâ”€â”€ 0.csv, 1.csv, ..., 9.csv  (10 files)
â”œâ”€â”€ valve2/
â”‚   â”œâ”€â”€ 0.csv, 1.csv, ..., 9.csv  (10 files)
â”œâ”€â”€ other/
â”‚   â”œâ”€â”€ 0.csv, 1.csv, ..., 4.csv  (5 files)
â””â”€â”€ anomaly-free/
    â”œâ”€â”€ 0.csv, 1.csv, ..., 4.csv  (5 files)
```

**ì‹¤í–‰**:
```python
# scripts/skab_full_evaluation.py

import subprocess
import json

skab_files = []
for subset in ["valve1", "valve2", "other"]:
    for i in range(10 if subset != "other" else 5):
        skab_files.append(f"{subset}/{i}.csv")

results = []
for file in skab_files:
    for detector in ["rule", "ml", "hybrid", "speccnn"]:
        for seed in [42, 142, 242]:  # 3 seeds per file
            cmd = [
                "python3", "-m", "experiments.main_experiment",
                "--dataset", "SKAB",
                "--data-root", "/workspace/data1/arsim/LFactory_d",
                "--detector", detector,
                "--file", file,
                "--seed", str(seed),
                "--run-id", f"skab_{file.replace('/', '_')}_{detector}_seed{seed}"
            ]

            if detector == "ml":
                for ml_method in ["knn", "isolation_forest", "lstm_ae"]:
                    cmd_ml = cmd + ["--ml-method", ml_method]
                    result = subprocess.run(cmd_ml, capture_output=True)
                    results.append({...})
            else:
                result = subprocess.run(cmd, capture_output=True)
                results.append({...})

# Total runs: 30 files Ã— 6 detectors Ã— 3 seeds = 540 runs
```

### 10.2 íŒŒì¼ë³„ ë‚œì´ë„ ë¶„ì„

**ë¶„ì„**:
1. **íŒŒì¼ë³„ anomaly rate**
   - anomaly-free: 0%
   - valve1: í‰ê·  35%
   - valve2: í‰ê·  ??%
   - other: í‰ê·  ??%

2. **íŒŒì¼ë³„ ìµœì  ì•Œê³ ë¦¬ì¦˜**
   - ì‰¬ìš´ íŒŒì¼ (ë†’ì€ anomaly rate): ëª¨ë“  detector ì„±ê³µ
   - ì–´ë ¤ìš´ íŒŒì¼ (ë‚®ì€ anomaly rate): LSTM-AEë§Œ ì„±ê³µ

3. **Cross-file ì¼ë°˜í™”**
   - valve1ì—ì„œ í•™ìŠµ â†’ valve2ì—ì„œ í…ŒìŠ¤íŠ¸
   - Transfer learning ê°€ëŠ¥ì„±

### 10.3 Ensemble ì „ëµ

**ì•„ì´ë””ì–´**: íŒŒì¼ íŠ¹ì„±ì— ë”°ë¼ detector ìë™ ì„ íƒ

**ë°©ë²•**:
1. **Meta-learning**:
   - Input: íŒŒì¼ í†µê³„ (ê¸¸ì´, anomaly rate, ë¶„ì‚°, ...)
   - Output: ìµœì  detector ì˜ˆì¸¡

2. **Voting ensemble**:
   - 3ê°œ detectorì˜ majority vote
   - Weighted voting (ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜)

3. **Stacking**:
   - Level 1: 6ê°œ detector ì˜ˆì¸¡
   - Level 2: Meta-modelì´ ìµœì¢… ê²°ì •

---

## Stage 11: AIHub71802 ë°ì´í„° ë¬¸ì œ í•´ê²° (1ì¼)

### ëª©í‘œ
AIHub71802 zero performance ì›ì¸ ê·œëª… ë° í•´ê²°

### 11.1 ë°ì´í„° ê²€ì‚¬

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# scripts/debug_aihub.py

import pandas as pd
import numpy as np

# 1. Load data
data_path = "/workspace/data1/arsim/LFactory_d/manufacturing_transport_71802/Validation/sensor/..."
label_path = "/workspace/data1/arsim/LFactory_d/manufacturing_transport_71802/Validation/label/..."

data = pd.read_csv(data_path)
labels = pd.read_csv(label_path)

# 2. Check data structure
print(f"Data shape: {data.shape}")
print(f"Label shape: {labels.shape}")
print(f"Data columns: {data.columns.tolist()}")
print(f"Label columns: {labels.columns.tolist()}")

# 3. Check label distribution
print(f"Label distribution:\n{labels.value_counts()}")

# 4. Check for NaN
print(f"Data NaN: {data.isna().sum().sum()}")
print(f"Label NaN: {labels.isna().sum().sum()}")

# 5. Check alignment
print(f"Data length: {len(data)}")
print(f"Label length: {len(labels)}")

# 6. Sample visualization
import matplotlib.pyplot as plt
plt.figure(figsize=(15, 5))
plt.plot(data.iloc[:, 0].values[:1000], label="Sensor Value")
plt.plot(labels.iloc[:, 0].values[:1000] * data.iloc[:, 0].max(), label="Label (scaled)", alpha=0.5)
plt.legend()
plt.savefig("aihub_sample.png")
```

### 11.2 ë¬¸ì œë³„ í•´ê²° ë°©ì•ˆ

**Problem 1**: ë¼ë²¨ì´ ëª¨ë‘ 0
- **Solution**: Training split ì‚¬ìš© (Validationì´ anomaly ì—†ì„ ìˆ˜ ìˆìŒ)

**Problem 2**: ì„¼ì„œ ë°ì´í„° í˜•ì‹ ë¶ˆì¼ì¹˜
- **Solution**: Loader ìˆ˜ì •, ë°ì´í„° ì •ê·œí™” ì¬ê²€í† 

**Problem 3**: Multi-modal fusion í•„ìš”
- **Solution**: Image modality ì¶”ê°€ (advanced, Phase 3)

**Problem 4**: Label scheme ë¶ˆì¼ì¹˜
- **Solution**: binary vs risk4 í™•ì¸, ì˜¬ë°”ë¥¸ scheme ì„ íƒ

### 11.3 ìˆ˜ì • í›„ ì¬ì‹¤í—˜

í•´ê²° í›„:
1. 6 detectors Ã— 20 seeds = 120 runs
2. ì„±ëŠ¥ ì¸¡ì •
3. COMPREHENSIVE_REPORT ì—…ë°ì´íŠ¸

---

## Stage 12: Phase 2 - Explain êµ¬í˜„ (3-4ì£¼)

### ëª©í‘œ
Anomaly detection ê²°ê³¼ì— ëŒ€í•œ **ìì—°ì–´ ì„¤ëª… ìë™ ìƒì„±**

### 12.1 LLM í†µí•© (Week 1: 5-7ì¼)

#### Option A: OpenAI API
```python
# experiments/llm_explainer.py

import openai

class LLMExplainer:
    def __init__(self, api_key=None, model="gpt-4"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        openai.api_key = self.api_key
        self.model = model

    def explain_anomaly(self, context):
        """Generate natural language explanation for anomaly."""
        prompt = self._build_prompt(context)

        response = openai.ChatCompletion.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "You are an expert in industrial anomaly detection."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=300
        )

        return response.choices[0].message.content

    def _build_prompt(self, context):
        """Build prompt from detection context."""
        template = f"""
        An anomaly was detected in {context['dataset']} data using {context['detector']}.

        **Detection Details**:
        - Time: {context['timestamp']}
        - Anomaly score: {context['score']:.3f}
        - Threshold: {context['threshold']:.3f}
        - Sensor values: {context['values']}
        - Historical average: {context['historical_avg']}
        - Deviation: {context['deviation']:.1f}%

        **Context**:
        - Previous 10 timesteps: {context['history']}
        - Detector type: {context['detector_type']}
        - Feature importance: {context['feature_importance']}

        Please provide:
        1. **What happened**: Describe the anomaly in simple terms
        2. **Why it's anomalous**: Explain why the detector flagged this
        3. **Possible causes**: List 2-3 potential root causes
        4. **Recommended actions**: Suggest next steps for operators

        Format the response in a clear, actionable manner for industrial operators.
        """
        return template
```

#### Option B: Local EXAONE Model
```python
from transformers import AutoTokenizer, AutoModelForCausalLM

class LocalLLMExplainer:
    def __init__(self, model_name="LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map="auto"
        )

    def explain_anomaly(self, context):
        prompt = self._build_prompt(context)
        inputs = self.tokenizer(prompt, return_tensors="pt").to("cuda")

        outputs = self.model.generate(
            **inputs,
            max_new_tokens=300,
            temperature=0.7,
            do_sample=True
        )

        explanation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return explanation
```

**ì„ íƒ ê¸°ì¤€**:
- **OpenAI**: í’ˆì§ˆ ìµœê³ , ë¹„ìš© ë°œìƒ, ì™¸ë¶€ ì˜ì¡´ì„±
- **Local EXAONE**: ë¬´ë£Œ, í”„ë¼ì´ë²„ì‹œ, GPU í•„ìš” (7.8B model)

**êµ¬í˜„ ì‘ì—…**:
1. [x] LLM wrapper í´ë˜ìŠ¤ ì‘ì„±
2. [ ] Prompt template ì„¤ê³„ (5-10ê°œ ì˜ˆì‹œ)
3. [ ] API key ê´€ë¦¬ (í™˜ê²½ë³€ìˆ˜)
4. [ ] Rate limiting (OpenAI API ì œí•œ ê³ ë ¤)
5. [ ] Error handling (API ì‹¤íŒ¨, timeout)

### 12.2 RAG (Retrieval-Augmented Generation) (Week 2: 5-7ì¼)

#### ëª©í‘œ
ë„ë©”ì¸ ì§€ì‹ì„ LLMì— ì£¼ì…í•˜ì—¬ ì„¤ëª… í’ˆì§ˆ í–¥ìƒ

#### ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•
```python
# experiments/knowledge_base.py

knowledge_base = {
    "SKAB": {
        "domain": "Industrial valve monitoring",
        "sensors": {
            "TE1": "Temperature sensor 1 (inlet)",
            "TE2": "Temperature sensor 2 (outlet)",
            "P1": "Pressure sensor (inlet)",
            "P2": "Pressure sensor (outlet)",
            "F1": "Flow rate sensor"
        },
        "common_anomalies": [
            {
                "type": "Valve stuck",
                "symptoms": "P1 increases, F1 decreases suddenly",
                "causes": ["Mechanical failure", "Foreign object", "Corrosion"],
                "actions": ["Inspect valve", "Check for blockage", "Replace if needed"]
            },
            {
                "type": "Temperature spike",
                "symptoms": "TE1 or TE2 > 80Â°C",
                "causes": ["Cooling system failure", "Excessive friction", "External heat"],
                "actions": ["Check cooling system", "Reduce load", "Emergency shutdown if >90Â°C"]
            }
        ]
    },
    "SMD": {
        "domain": "Server monitoring",
        "metrics": {
            "cpu_usage": "CPU utilization (%)",
            "memory": "Memory usage (MB)",
            "disk_io": "Disk I/O operations/sec",
            "network_in": "Network incoming traffic (MB/s)"
        },
        "common_anomalies": [
            {
                "type": "CPU spike",
                "symptoms": "CPU > 90% for extended period",
                "causes": ["Runaway process", "DDoS attack", "Memory leak"],
                "actions": ["Identify process (top/htop)", "Kill if malicious", "Restart service"]
            }
        ]
    }
}
```

#### Retrieval êµ¬í˜„
```python
# TF-IDF ê¸°ë°˜ ê°„ë‹¨í•œ retrieval
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class KnowledgeRetriever:
    def __init__(self, knowledge_base):
        self.kb = knowledge_base
        self.vectorizer = TfidfVectorizer()

        # Index all knowledge
        self.documents = []
        self.metadata = []
        for domain, data in knowledge_base.items():
            for anomaly in data.get("common_anomalies", []):
                doc = f"{anomaly['type']} {anomaly['symptoms']} {' '.join(anomaly['causes'])}"
                self.documents.append(doc)
                self.metadata.append({"domain": domain, "anomaly": anomaly})

        self.tfidf_matrix = self.vectorizer.fit_transform(self.documents)

    def retrieve(self, query, top_k=3):
        """Retrieve top-k relevant knowledge entries."""
        query_vec = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vec, self.tfidf_matrix)[0]

        top_indices = similarities.argsort()[-top_k:][::-1]
        results = [self.metadata[i] for i in top_indices]
        return results
```

#### RAG í†µí•©
```python
class RAGExplainer:
    def __init__(self, llm, retriever):
        self.llm = llm
        self.retriever = retriever

    def explain_anomaly(self, context):
        # 1. Retrieve relevant knowledge
        query = f"{context['dataset']} {context['sensor']} anomaly score {context['score']}"
        knowledge = self.retriever.retrieve(query, top_k=3)

        # 2. Augment prompt with retrieved knowledge
        prompt = self._build_rag_prompt(context, knowledge)

        # 3. Generate explanation
        explanation = self.llm.explain_anomaly({"prompt": prompt})
        return explanation

    def _build_rag_prompt(self, context, knowledge):
        kb_text = "\n\n".join([
            f"**{k['anomaly']['type']}**:\n"
            f"- Symptoms: {k['anomaly']['symptoms']}\n"
            f"- Causes: {', '.join(k['anomaly']['causes'])}\n"
            f"- Actions: {', '.join(k['anomaly']['actions'])}"
            for k in knowledge
        ])

        template = f"""
        You are an expert in {context['dataset']} anomaly detection.

        **Relevant Domain Knowledge**:
        {kb_text}

        **Current Anomaly**:
        {context}

        Based on the domain knowledge above, explain this anomaly.
        """
        return template
```

**ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸**:
1. [ ] ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ ì‘ì„± (SKAB, SMD, Synthetic)
2. [ ] TF-IDF retriever êµ¬í˜„
3. [ ] RAG prompt template ì„¤ê³„
4. [ ] End-to-end í…ŒìŠ¤íŠ¸ (5-10ê°œ ìƒ˜í”Œ)
5. [ ] ì„¤ëª… í’ˆì§ˆ í‰ê°€ (ì‚¬ëŒ í‰ê°€ or GPT-4 as judge)

### 12.3 Bayesian Prior for Cost Matrix (Week 3: 5-7ì¼)

#### ëª©í‘œ
ì‚¬ìš©ì í”¼ë“œë°±ì„ í•™ìŠµí•˜ì—¬ cost matrix ë™ì  ì¡°ì •

#### ì‹œë‚˜ë¦¬ì˜¤
```
User marks FP as "acceptable" â†’ Reduce C_FP
User marks FN as "critical" â†’ Increase C_FN
```

#### Bayesian Update
```python
# experiments/bayesian_cost_learner.py

import numpy as np
from scipy import stats

class BayesianCostLearner:
    def __init__(self, prior_c_fp=1.0, prior_c_fn=5.0):
        """Initialize with prior cost matrix."""
        self.c_fp_prior = stats.gamma(a=2, scale=prior_c_fp/2)  # Gamma distribution
        self.c_fn_prior = stats.gamma(a=2, scale=prior_c_fn/2)

        # Posterior (updated with feedback)
        self.c_fp_posterior = self.c_fp_prior
        self.c_fn_posterior = self.c_fn_prior

    def update(self, feedback):
        """Update cost matrix based on user feedback.

        Args:
            feedback: dict with keys:
                - type: "FP" or "FN"
                - severity: float in [0, 10]
        """
        if feedback["type"] == "FP":
            # Update FP cost
            # Higher severity â†’ higher cost
            observed_cost = feedback["severity"]
            self.c_fp_posterior = self._bayesian_update(
                self.c_fp_posterior, observed_cost
            )
        elif feedback["type"] == "FN":
            observed_cost = feedback["severity"]
            self.c_fn_posterior = self._bayesian_update(
                self.c_fn_posterior, observed_cost
            )

    def _bayesian_update(self, prior, observation):
        """Bayesian update using conjugate prior."""
        # Simplified: use sample mean as posterior
        # In practice, use proper Bayesian inference
        prior_mean = prior.mean()
        posterior_mean = 0.8 * prior_mean + 0.2 * observation  # Weighted average
        return stats.gamma(a=2, scale=posterior_mean/2)

    def get_cost_matrix(self):
        """Return current cost matrix estimate."""
        return {
            "c00": 0.0,
            "c01": self.c_fp_posterior.mean(),
            "c10": self.c_fn_posterior.mean(),
            "c11": 0.0
        }
```

#### Feedback Collection UI (ê°„ë‹¨í•œ CLI)
```python
def collect_feedback():
    """Collect user feedback on detection result."""
    print("Detection result: Anomaly detected at t=1234")
    print("Ground truth: Normal")
    print("This is a False Positive (FP).")

    severity = input("How severe is this false alarm? (0=harmless, 10=critical): ")
    severity = float(severity)

    return {"type": "FP", "severity": severity}
```

**ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸**:
1. [ ] Bayesian update ìˆ˜ì‹ ê²€ì¦
2. [ ] Feedback collection mechanism
3. [ ] A/B test: Fixed cost vs Adaptive cost
4. [ ] Simulation: 100 feedback cycles
5. [ ] ìˆ˜ë ´ ì†ë„ ë¶„ì„ (ëª‡ ë²ˆ feedback í›„ ì•ˆì •í™”?)

### 12.4 End-to-End íŒŒì´í”„ë¼ì¸ í†µí•© (Week 4: 3-5ì¼)

#### ëª©í‘œ
Detect + Explain + Learn ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

#### í†µí•© ì‹œìŠ¤í…œ
```python
# experiments/end_to_end_pipeline.py

class AnomalyDetectionPipeline:
    def __init__(self, detector, explainer, cost_learner):
        self.detector = detector
        self.explainer = explainer
        self.cost_learner = cost_learner

    def process_stream(self, data_stream):
        """Process time series stream with detection, explanation, and learning."""
        for t, value in enumerate(data_stream):
            # 1. Detect
            score = self.detector.get_score(value)
            threshold = self.detector.get_threshold(
                cost_matrix=self.cost_learner.get_cost_matrix()
            )
            is_anomaly = score > threshold

            if is_anomaly:
                # 2. Explain
                context = {
                    "timestamp": t,
                    "value": value,
                    "score": score,
                    "threshold": threshold,
                    "history": data_stream[max(0, t-10):t],
                    "detector": self.detector.name
                }
                explanation = self.explainer.explain_anomaly(context)

                # 3. Present to user
                print(f"âš ï¸ Anomaly at t={t}")
                print(f"Score: {score:.3f} (threshold: {threshold:.3f})")
                print(f"\n{explanation}\n")

                # 4. Collect feedback
                feedback = self.collect_feedback(t, value, is_anomaly)

                # 5. Learn
                if feedback:
                    self.cost_learner.update(feedback)
                    print(f"âœ… Cost matrix updated: {self.cost_learner.get_cost_matrix()}")

    def collect_feedback(self, t, value, predicted_anomaly):
        """Collect user feedback (simulation or real user)."""
        # In real system, prompt user
        # For simulation, use ground truth
        ground_truth = self.get_ground_truth(t)

        if predicted_anomaly and not ground_truth:
            # False Positive
            severity = random.uniform(1, 5)  # Simulate user rating
            return {"type": "FP", "severity": severity}
        elif not predicted_anomaly and ground_truth:
            # False Negative
            severity = random.uniform(5, 10)  # FN more severe
            return {"type": "FN", "severity": severity}
        else:
            # Correct prediction, no feedback needed
            return None
```

#### ì‹¤í–‰ ì˜ˆì‹œ
```python
# Demo script
detector = IsolationForestDetector(...)
explainer = RAGExplainer(llm=OpenAILLM(), retriever=KnowledgeRetriever(...))
learner = BayesianCostLearner(prior_c_fp=1.0, prior_c_fn=5.0)

pipeline = AnomalyDetectionPipeline(detector, explainer, learner)

# Load SKAB data
data = load_skab("valve1/0.csv")
pipeline.process_stream(data["values"])
```

**ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸**:
1. [ ] Pipeline í´ë˜ìŠ¤ êµ¬í˜„
2. [ ] Streaming mode êµ¬í˜„
3. [ ] Feedback loop í…ŒìŠ¤íŠ¸
4. [ ] ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ (CLI or Web)
5. [ ] Demo ë¹„ë””ì˜¤ ë…¹í™”

### 12.5 Phase 2 í‰ê°€ (Week 4: 2ì¼)

#### ì„¤ëª… í’ˆì§ˆ í‰ê°€

**Metrics**:
1. **Faithfulness**: ì„¤ëª…ì´ ì‹¤ì œ detector ë™ì‘ì„ ì •í™•íˆ ë°˜ì˜í•˜ëŠ”ê°€?
   - Method: ì„¤ëª…ì—ì„œ ì–¸ê¸‰í•œ featureë¥¼ ablation â†’ score ë³€í™” ì¸¡ì •
   - Good explanation: ì–¸ê¸‰í•œ feature ì œê±° ì‹œ score í¬ê²Œ ë³€í™”

2. **Plausibility**: ì„¤ëª…ì´ ë„ë©”ì¸ ì „ë¬¸ê°€ì—ê²Œ í•©ë¦¬ì ì¸ê°€?
   - Method: ì‚¬ëŒ í‰ê°€ (5-point Likert scale)
   - 5-10ëª… í‰ê°€ì, 10-20ê°œ ìƒ˜í”Œ

3. **Actionability**: ì„¤ëª…ì´ êµ¬ì²´ì ì¸ ì¡°ì¹˜ë¥¼ ì œì•ˆí•˜ëŠ”ê°€?
   - Method: Count actionable items (e.g., "Check valve", "Restart server")

#### Bayesian Learning í‰ê°€

**Metrics**:
1. **Convergence speed**: ëª‡ ë²ˆì˜ feedback í›„ cost matrix ì•ˆì •í™”?
2. **Final accuracy**: ìµœì¢… learned cost vs ground-truth cost
3. **Regret**: Cumulative cost over time (early mistakes)

#### ìµœì¢… ë³´ê³ ì„œ

**ì¶œë ¥ë¬¼**: `PHASE2_EXPLANATION_REPORT.md`

**êµ¬ì¡°**:
1. **Introduction**: Phase 2 ëª©í‘œ ë° ì ‘ê·¼ë²•
2. **LLM Integration**: OpenAI vs Local EXAONE ë¹„êµ
3. **RAG System**: ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ë° retrieval ì„±ëŠ¥
4. **Bayesian Learning**: Cost matrix adaptation ì‹¤í—˜ ê²°ê³¼
5. **Case Studies**: 5-10ê°œ ì‹¤ì œ anomaly ì„¤ëª… ì˜ˆì‹œ
6. **User Study**: ì‚¬ëŒ í‰ê°€ ê²°ê³¼ (if available)
7. **Limitations & Future Work**

---

# ğŸ“… ì „ì²´ ì¼ì • (Timeline)

## Week 1-2: Phase 1.5 - Detect ê³ ë„í™”

| ë‚ ì§œ | Stage | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ |
|------|-------|------|-----------|
| Day 1-2 | Stage 7.1-7.2 | ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” + ë°ì´í„°ì…‹ë³„ ë¶„ì„ | 2ì¼ |
| Day 3 | Stage 7.3-7.4 | í¬ë¡œìŠ¤ ë°ì´í„°ì…‹ ë¶„ì„ + Ablation ì„¤ê³„ | 1ì¼ |
| Day 4-5 | Stage 7.5 | ë…¼ë¬¸ ì‘ì„± (ì´ˆì•ˆ) | 2ì¼ |
| Day 6 | Stage 8 | SpecCNN weight ìµœì í™” | 1ì¼ |
| Day 7-9 | Stage 9 | í•˜ì´í¼íŒŒë¼ë¯¸í„° Bayesian ìµœì í™” | 3ì¼ |
| Day 10-12 | Stage 10 | SKAB ì „ì²´ íŒŒì¼ í‰ê°€ | 3ì¼ |
| Day 13 | Stage 11 | AIHub71802 ë””ë²„ê¹… | 1ì¼ |
| Day 14 | - | ë²„í¼ / ë¦¬ë·° | 1ì¼ |

**Milestone 1 (Week 2 ì™„ë£Œ)**:
- âœ… ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë…¼ë¬¸ ì´ˆì•ˆ ì™„ì„±
- âœ… ëª¨ë“  detector ìµœì í™” ì™„ë£Œ
- âœ… 4ê°œ ë°ì´í„°ì…‹ ì™„ì „ í‰ê°€

## Week 3-6: Phase 2 - Explain

| ë‚ ì§œ | Stage | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ |
|------|-------|------|-----------|
| Day 15-17 | Stage 12.1 | LLM í†µí•© (OpenAI + Local EXAONE) | 3ì¼ |
| Day 18-19 | Stage 12.1 | Prompt engineering | 2ì¼ |
| Day 20-22 | Stage 12.2 | RAG êµ¬í˜„ (ì§€ì‹ ë² ì´ìŠ¤ + Retrieval) | 3ì¼ |
| Day 23-24 | Stage 12.2 | RAG í…ŒìŠ¤íŠ¸ ë° í‰ê°€ | 2ì¼ |
| Day 25-27 | Stage 12.3 | Bayesian cost learner êµ¬í˜„ | 3ì¼ |
| Day 28-29 | Stage 12.3 | Feedback simulation ë° A/B test | 2ì¼ |
| Day 30-32 | Stage 12.4 | End-to-end íŒŒì´í”„ë¼ì¸ í†µí•© | 3ì¼ |
| Day 33-34 | Stage 12.4 | ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ (CLI/Web) | 2ì¼ |
| Day 35-36 | Stage 12.5 | Phase 2 í‰ê°€ ë° ë³´ê³ ì„œ | 2ì¼ |
| Day 37-40 | - | ë²„í¼ / ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ / ìˆ˜ì • | 4ì¼ |

**Milestone 2 (Week 6 ì™„ë£Œ)**:
- âœ… LLM ê¸°ë°˜ ì„¤ëª… ìƒì„± ì‹œìŠ¤í…œ ì™„ì„±
- âœ… RAG ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•
- âœ… Bayesian cost learning ì‘ë™
- âœ… Phase 2 ë³´ê³ ì„œ ì™„ì„±

---

# ğŸ¯ í•µì‹¬ ì„±ê³¼ë¬¼ (Deliverables)

## Phase 1.5 ì„±ê³¼ë¬¼

### 1. ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë…¼ë¬¸
- **íŒŒì¼**: `ALGORITHM_COMPARISON_PAPER.pdf`
- **í˜ì´ì§€**: 10-12 pages (IEEE format)
- **ë‚´ìš©**: RQ1-4 ë‹µë³€, í†µê³„ ê²€ì •, ë¹„êµ ë¶„ì„
- **ëª©í‘œ**: IEEE TKDE íˆ¬ê³ 

### 2. ì‹œê°í™” íŒ¨í‚¤ì§€
- **ë””ë ‰í† ë¦¬**: `figures/`
- **ë‚´ìš©**:
  - Performance comparison charts (7ê°œ)
  - Statistical heatmaps (2ê°œ)
  - ROC/PR curves (3Ã—6=18ê°œ)
  - Calibration diagrams (3Ã—6=18ê°œ)
- **í˜•ì‹**: PNG (300 DPI), PDF (vector)

### 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì´ë“œ
- **íŒŒì¼**: `HYPERPARAMETER_GUIDE.md`
- **ë‚´ìš©**:
  - ê° detector Ã— dataset ìµœì  ì„¤ì •
  - Sensitivity analysis
  - Tuning workflow

### 4. SKAB ì „ì²´ í‰ê°€ ë³´ê³ ì„œ
- **íŒŒì¼**: `SKAB_FULL_EVALUATION.md`
- **ë‚´ìš©**:
  - 30ê°œ íŒŒì¼ë³„ ì„±ëŠ¥
  - íŒŒì¼ ë‚œì´ë„ ë¶„ì„
  - Cross-file ì¼ë°˜í™”

### 5. ì—…ë°ì´íŠ¸ëœ ì¢…í•© ë³´ê³ ì„œ
- **íŒŒì¼**: `COMPREHENSIVE_EXPERIMENT_REPORT_v2.md`
- **ë³€ê²½ì‚¬í•­**:
  - SpecCNN ìµœì í™” ê²°ê³¼ ì¶”ê°€
  - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì  ì„¤ì • ë°˜ì˜
  - AIHub71802 ìˆ˜ì • ê²°ê³¼

## Phase 2 ì„±ê³¼ë¬¼

### 1. LLM ì„¤ëª… ì‹œìŠ¤í…œ
- **ë””ë ‰í† ë¦¬**: `experiments/llm/`
- **íŒŒì¼**:
  - `llm_explainer.py` - OpenAI wrapper
  - `local_llm_explainer.py` - EXAONE wrapper
  - `prompt_templates.py` - 10ê°œ í…œí”Œë¦¿
- **Demo**: 5-10ê°œ anomaly ì„¤ëª… ìƒ˜í”Œ

### 2. RAG ì§€ì‹ ë² ì´ìŠ¤
- **íŒŒì¼**: `knowledge_base.json`
- **ë‚´ìš©**:
  - SKAB: 10ê°œ common anomalies
  - SMD: 8ê°œ common anomalies
  - Synthetic: 5ê°œ pattern types
- **í¬ê¸°**: ~500 entries

### 3. Bayesian Cost Learner
- **íŒŒì¼**: `bayesian_cost_learner.py`
- **ê¸°ëŠ¥**:
  - Feedback collection
  - Bayesian update
  - A/B test framework
- **Validation**: 100-iteration simulation

### 4. End-to-End íŒŒì´í”„ë¼ì¸
- **íŒŒì¼**: `end_to_end_pipeline.py`
- **ê¸°ëŠ¥**:
  - Streaming detection
  - Real-time explanation
  - Interactive feedback
- **Interface**: CLI (ê¸°ë³¸) + Web (ì„ íƒ)

### 5. Phase 2 ìµœì¢… ë³´ê³ ì„œ
- **íŒŒì¼**: `PHASE2_EXPLANATION_REPORT.md`
- **í˜ì´ì§€**: 20-25 pages
- **ë‚´ìš©**:
  - LLM integration ë¹„êµ
  - RAG system í‰ê°€
  - Bayesian learning ì‹¤í—˜
  - Case studies (5-10ê°œ)
  - User study ê²°ê³¼

### 6. Demo ë¹„ë””ì˜¤
- **íŒŒì¼**: `demo.mp4`
- **ê¸¸ì´**: 5-10ë¶„
- **ë‚´ìš©**:
  - Live anomaly detection
  - Explanation generation
  - Feedback & learning
- **í˜•ì‹**: Screen recording + narration

---

# ğŸ“Š ì„±ê³µ ì§€í‘œ (Success Metrics)

## Phase 1.5 ëª©í‘œ

| Metric | Target | Measurement |
|--------|--------|-------------|
| **SpecCNN AUC-PR** | > 0.3 (í˜„ì¬ 0) | Grid search í›„ ì¬ì¸¡ì • |
| **IsolationForest ê°œì„ ** | +15% AUC-PR | Optimized vs Baseline |
| **LSTM-AE ê°œì„ ** | +10% F1 | Optimized vs Baseline |
| **SKAB ì „ì²´ í‰ê°€** | 30 files Ã— 6 detectors | 180 runs ì™„ë£Œ |
| **ë…¼ë¬¸ ì‘ì„±** | 10-12 pages | Peer review ready |

## Phase 2 ëª©í‘œ

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Explanation Faithfulness** | > 0.7 | Feature ablation test |
| **Explanation Plausibility** | > 4.0/5.0 | Human evaluation (5 judges) |
| **Actionability** | > 2 actions/explanation | Automatic counting |
| **Cost Matrix Convergence** | < 20 feedbacks | Simulation |
| **User Satisfaction** | > 4.0/5.0 | User study (10 users) |

---

# ğŸ”§ ê°œë°œ í™˜ê²½ ë° ë„êµ¬

## í•„ìš”í•œ ì¶”ê°€ íŒ¨í‚¤ì§€

```bash
# LLM
pip install openai transformers accelerate

# Bayesian Optimization
pip install scikit-optimize bayesian-optimization

# Visualization
pip install seaborn plotly

# Web UI (optional)
pip install streamlit fastapi

# Evaluation
pip install rouge_score bert_score
```

## í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

### Phase 1.5 (í˜„ì¬ í™˜ê²½ìœ¼ë¡œ ì¶©ë¶„)
- CPU: 8+ cores
- RAM: 16GB
- GPU: Optional (LSTM-AE ê°€ì†ìš©)

### Phase 2
- CPU: 8+ cores
- RAM: 32GB (Local LLM ì‚¬ìš© ì‹œ)
- GPU: 16GB+ VRAM (EXAONE-7.8B ì‹¤í–‰ ì‹œ)
  - RTX 3090, A6000, A100 ê¶Œì¥

**ëŒ€ì•ˆ**: OpenAI API ì‚¬ìš© (GPU ë¶ˆí•„ìš”, ë¹„ìš© ë°œìƒ)

---

# âš ï¸ ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ

## Phase 1.5 ìœ„í—˜

| ìœ„í—˜ | í™•ë¥  | ì˜í–¥ | ëŒ€ì‘ ë°©ì•ˆ |
|------|------|------|-----------|
| SpecCNN grid search ì‹œê°„ ì´ˆê³¼ | ì¤‘ | ì¤‘ | Random search 20% ì‚¬ìš© |
| LSTM-AE ìµœì í™” ë„ˆë¬´ ëŠë¦¼ | ê³  | ì¤‘ | Early stopping, smaller grid |
| SKAB ë‹¤ì¤‘ íŒŒì¼ì—ì„œ ì„±ëŠ¥ ì €í•˜ | ì¤‘ | ì¤‘ | Ensemble ì „ëµ ì ìš© |
| AIHub71802 ë°ì´í„° ë³µêµ¬ ì‹¤íŒ¨ | ì¤‘ | ì € | 3ê°œ ë°ì´í„°ì…‹ë§Œìœ¼ë¡œ ì§„í–‰ |

## Phase 2 ìœ„í—˜

| ìœ„í—˜ | í™•ë¥  | ì˜í–¥ | ëŒ€ì‘ ë°©ì•ˆ |
|------|------|------|-----------|
| OpenAI API ë¹„ìš© ì´ˆê³¼ | ì¤‘ | ì¤‘ | Local EXAONEìœ¼ë¡œ ì „í™˜ |
| EXAONE GPU ë©”ëª¨ë¦¬ ë¶€ì¡± | ì¤‘ | ê³  | Quantization (4-bit), Smaller model |
| ì„¤ëª… í’ˆì§ˆ ë‚®ìŒ | ì¤‘ | ê³  | Prompt engineering ë°˜ë³µ, RAG ê°•í™” |
| Bayesian learning ìˆ˜ë ´ ì•ˆ ë¨ | ì € | ì¤‘ | ë‹¤ë¥¸ prior ì‹œë„, Beta distribution |
| ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ ëª¨ì§‘ ì‹¤íŒ¨ | ì¤‘ | ì € | Simulated feedback ì‚¬ìš© |

---

# ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½

## Phase 1.5 (Week 1-2)
- [ ] Stage 7: ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë³´ê³ ì„œ
  - [ ] 7.1 ì‹œê°í™” ìƒì„± (7ê°œ ì°¨íŠ¸)
  - [ ] 7.2 ë°ì´í„°ì…‹ë³„ ë¶„ì„
  - [ ] 7.3 í¬ë¡œìŠ¤ ë°ì´í„°ì…‹ ì¼ë°˜í™”
  - [ ] 7.4 Ablation study í™•ì¥
  - [ ] 7.5 ë…¼ë¬¸ ì‘ì„± (10-12 pages)
- [ ] Stage 8: SpecCNN ìµœì í™”
  - [ ] 8.1 Grid search (216 combinations)
  - [ ] 8.2 ìµœì  weightsë¡œ ì¬ì‹¤í—˜
  - [ ] 8.3 Frequency-domain ë¶„ì„
- [ ] Stage 9: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
  - [ ] 9.1 Bayesian optimization êµ¬í˜„
  - [ ] 9.2 ë°ì´í„°ì…‹ë³„ ìµœì  ì„¤ì •
  - [ ] 9.3 ìµœì  ì„¤ì •ìœ¼ë¡œ ì¬ì‹¤í—˜
- [ ] Stage 10: SKAB ì „ì²´ í‰ê°€
  - [ ] 10.1 30ê°œ íŒŒì¼ ì‹¤í—˜
  - [ ] 10.2 íŒŒì¼ë³„ ë‚œì´ë„ ë¶„ì„
  - [ ] 10.3 Ensemble ì „ëµ
- [ ] Stage 11: AIHub71802 ë””ë²„ê¹…
  - [ ] 11.1 ë°ì´í„° ê²€ì‚¬
  - [ ] 11.2 ë¬¸ì œ í•´ê²°
  - [ ] 11.3 ì¬ì‹¤í—˜

## Phase 2 (Week 3-6)
- [ ] Stage 12.1: LLM í†µí•©
  - [ ] OpenAI API wrapper
  - [ ] Local EXAONE wrapper
  - [ ] Prompt template ì„¤ê³„
  - [ ] Error handling
- [ ] Stage 12.2: RAG êµ¬í˜„
  - [ ] ì§€ì‹ ë² ì´ìŠ¤ ì‘ì„±
  - [ ] TF-IDF retriever
  - [ ] RAG prompt template
  - [ ] End-to-end í…ŒìŠ¤íŠ¸
- [ ] Stage 12.3: Bayesian Cost Learning
  - [ ] Bayesian update êµ¬í˜„
  - [ ] Feedback collection
  - [ ] A/B test
  - [ ] Simulation (100 iterations)
- [ ] Stage 12.4: íŒŒì´í”„ë¼ì¸ í†µí•©
  - [ ] End-to-end pipeline
  - [ ] Streaming mode
  - [ ] User interface (CLI/Web)
  - [ ] Demo ë¹„ë””ì˜¤
- [ ] Stage 12.5: Phase 2 í‰ê°€
  - [ ] ì„¤ëª… í’ˆì§ˆ í‰ê°€
  - [ ] Bayesian learning í‰ê°€
  - [ ] ìµœì¢… ë³´ê³ ì„œ

---

# ğŸ“ í•™ìŠµ ë° ì°¸ê³  ìë£Œ

## Phase 1.5 ì°¸ê³  ë…¼ë¬¸
1. Hyperparameter Optimization:
   - Bergstra & Bengio (2012) - Random Search
   - Snoek et al. (2012) - Bayesian Optimization

2. Time Series Anomaly Detection:
   - Su et al. (2019) - Robust Anomaly Detection for Multivariate Time Series
   - Lai et al. (2021) - Revisiting Time Series Outlier Detection

3. Frequency-Domain Methods:
   - Cleveland et al. (1990) - STL: Seasonal-Trend decomposition
   - Wen et al. (2020) - Spectral Residual for Anomaly Detection

## Phase 2 ì°¸ê³  ìë£Œ
1. LLM for Explanation:
   - Lewis et al. (2020) - RAG: Retrieval-Augmented Generation
   - Wei et al. (2022) - Chain-of-Thought Prompting

2. Explainable AI:
   - Ribeiro et al. (2016) - LIME
   - Lundberg & Lee (2017) - SHAP

3. Bayesian Learning:
   - Murphy (2012) - Machine Learning: A Probabilistic Perspective
   - Ghahramani (2015) - Probabilistic Machine Learning and AI

---

**ë¬¸ì„œ ì‘ì„±**: 2025-11-24
**ì˜ˆìƒ ì™„ë£Œ**: 2025-12-31 (Phase 1.5) + 2026-01-31 (Phase 2)
**ë‹´ë‹¹ì**: LFactory Team
**ìƒíƒœ**: ê³„íš ë‹¨ê³„ â†’ ì‹¤í–‰ ëŒ€ê¸°

---

**ë‹¤ìŒ ë‹¨ê³„**: Stage 7ë¶€í„° ì‹œì‘ (ì‚¬ìš©ì ìŠ¹ì¸ í›„)
