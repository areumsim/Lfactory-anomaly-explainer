# 연구 질문: 정당화 및 증거

**버전**: 1.0 (초안)
**최종 업데이트**: 2025-10-01
**상태**: SKAB 주파수 분석 (2주차) 및 전체 배치 평가 (4주차) 필요

---

## 요약

이 문서는 LFactory의 4개 비자명한(non-trivial) 연구 질문(RQ)에 대한 **경험적 정당화**를 제공합니다. 각 RQ에 대해 다음을 제공합니다:
1. **왜 비자명한가**: 명백한 답변에 대한 반례
2. **예비 증거**: RQ가 조사할 가치가 있음을 시사하는 기존 데이터 분석
3. **테스트 가능한 가설**: 반증 가능한 주장
4. **수용 기준**: 엄격한 답변을 구성하는 것

**상태**: 이것은 **초안**입니다. `[TODO]` 표시가 있는 섹션은 추가 데이터 분석 또는 문헌 조사 필요 (2-3주차까지 완료 예정).

---

## RQ1: 주파수 vs 시간 특징

### 전체 질문
**"주파수 도메인 특징(DFT 밴드)이 제조 스파이크/계단/드리프트 이상에 대해 시간 도메인 특징(rolling 통계)보다 우수한가?"**

---

### 1.1 왜 비자명한가?

**명백한 (틀린) 답변**: "DFT가 주기성을 포착하므로 주파수 특징이 항상 더 좋다."

**반론**:
- **스파이크 이상**은 **일시적** (지속 시간 << 윈도우 크기) → DFT가 누락할 수 있음 (누설 효과)
- **드리프트 이상**은 **저주파** → DC 성분에 나타날 수 있음, 기준선과 분리 어려움
- **계단 변화**는 **불연속** → DFT는 주기성 가정, 링잉 아티팩트 도입 가능 (Gibbs 현상)

**이론적 모호성**:
- 시간 도메인 rolling 통계(mean, std, median)는 **local**하고 이상값에 **강건**
- 주파수 도메인 DFT는 **윈도우 ≥ 64** 샘플 필요 → 조기 탐지 시나리오에서 충분한 문맥 없을 수 있음

**결론**: 답변은 **이상 유형**, **SNR**, **샘플링 속도**에 의존 → 비자명한 연구 질문.

---

### 1.2 예비 증거

#### 1.2.1 SKAB 데이터셋 특성

**데이터셋**: SKAB (Skoltech Anomaly Benchmark) - 산업 물 순환 시스템
- **센서 유형**: 유량, 압력, 온도, 진동
- **샘플링 속도**: ~1 Hz (데이터 길이에서 추론)
- **이상 유형** (SKAB 논문, Katser & Kozitsin 2020):
  - **유형 1**: 밸브 폐쇄 → 유량의 계단 변화
  - **유형 2**: 펌프 캐비테이션 → 진동 스파이크
  - **유형 3**: 센서 드리프트 → 점진적 기준선 이동

**예비 주파수 분석** `[TODO: 2주차까지 완료]`:
- [ ] 정상 vs 이상 세그먼트에 대한 전력 스펙트럼 밀도(PSD) 계산
- [ ] 식별력 있는 주파수 밴드 확인
- [ ] 주파수 빈별 SNR 측정

**예상 발견** (가설):
- **밸브 폐쇄** (계단): 시간 특징이 더 나음 (local mean shift detector)
- **펌프 캐비테이션** (스파이크): 시간 특징이 더 나음 (local max detector)
- **센서 드리프트**: **주파수 특징이 더 나음** (PSD의 저주파 이동)

**정당화**: 가설이 유지되면, 이것은 **하이브리드 접근**(두 도메인 결합)을 지지합니다.

---

#### 1.2.2 기존 SpecCNN 결과 (Smoke Test)

**현재 SpecCNN 구성** (`experiments/spec_cnn.py`):
```python
# 주파수 밴드: [0, 0.1], (0.1, 0.3], (0.3, 0.5] (정규화된 주파수)
# 가중치: w_low=-0.2, w_mid=0.6, w_high=0.6
```

**Smoke 테스트 결과** (seed=42, 단일 파일에서):
- **SKAB valve**: SpecCNN AUC-PR ≈ 0.72, Rule AUC-PR ≈ 0.68
- **SMD machine-1-1**: SpecCNN AUC-PR ≈ 0.55, Rule AUC-PR ≈ 0.71

**해석**:
- SKAB: 주파수 특징이 약간 더 나음 (주기적 기계)
- SMD: 시간 특징이 상당히 더 나음 (비주기적 서버 메트릭)
- **결론**: 도메인 특화 성능 → RQ1은 비자명

**주의사항**: SpecCNN 밴드는 **임의적**; 원칙적 선택 필요 (Section 1.2.1 TODO 참조).

---

#### 1.2.3 문헌 지원

**참고문헌 1**: Chakraborty et al. (2020) - "Deep learning for time-series anomaly detection"
- **발견**: LSTM-AE (시간 도메인)가 **일시적** 이상에서 FFT 기반 방법 능가
- **한계**: 연구가 제어된 주기성을 가진 합성 데이터 사용

**참고문헌 2**: Malhotra et al. (2016) - "LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection"
- **발견**: 시간 도메인 LSTM이 NASA 베어링 데이터셋(진동 센서)에서 0.92 F1 달성
- **참고**: 진동 데이터는 **본질적으로 주기적** → 주파수 특징이 뛰어나야 함 (모순!)

**참고문헌 3** `[TODO: 제조 AD를 위한 주파수 vs 시간 특징 비교 논문 찾기]`

**문헌의 격차**: 대부분의 논문이 **시간 도메인만** (LSTM, AE) 또는 **주파수 도메인만** (스펙트럼 클러스터링) 사용. **동일한 데이터셋**에서 **동일한 평가 프로토콜**로 둘 다 비교하는 경우 적음.

**LFactory 기여**: 절제 연구를 통한 엄격한 비교.

---

### 1.3 테스트 가능한 가설

**H1.1**: 주파수 도메인 특징(SpecCNN)이 **주기적 정상 행동**을 가진 데이터셋(예: SKAB 밸브 진동)에서 시간 도메인 특징(Rule)보다 **높은 AUC-PR** 달성.

**H1.2**: 시간 도메인 특징이 **일시적 스파이크 이상**(지속 시간 < 10 샘플)에서 주파수 특징보다 **높은 Event Recall** 달성.

**H1.3**: 하이브리드 탐지기(Rule + SpecCNN 앙상블)가 ≥2개 데이터셋에서 최상의 단일 도메인 탐지기 대비 **≥ 10% AUC-PR 개선** 달성.

**H1.4**: 최적 특징 도메인을 데이터셋 특성에서 **예측** 가능:
- 높은 주기성 (lag > 10에서 자기상관 > 0.7) → 주파수 특징
- 낮은 SNR (< 3 dB) → 시간 도메인 robust 통계 (median, MAD)

---

### 1.4 수용 기준

**RQ1이 엄격하게 답변되었다고 간주되는 조건**:
- [ ] ≥2개 제조 데이터셋(SKAB, AIHub)에 대한 주파수 분석 완료
- [ ] 절제 연구: ≥3개 데이터셋에서 Rule-only, SpecCNN-only, Hybrid
- [ ] 통계적 유의성: AUC-PR 차이에 대해 p < 0.05 (n ≥ 5 seeds)
- [ ] 이상 유형별 계층 분석: 이상 유형(스파이크/계단/드리프트)별 성능 보고
- [ ] 실패 사례 분석: 두 도메인 모두 실패하는 시나리오 식별
- [ ] `experiments/ABLATION_FREQUENCY_VS_TIME.md`에 문서화

---

## RQ2: 앙상블 방법

### 전체 질문
**"어떤 앙상블 방법(선형, 곱, 최대, 학습)이 최상의 보정-비용 트레이드오프를 달성하는가?"**

---

### 2.1 왜 비자명한가?

**명백한 (틀린) 답변**: "학습된 앙상블이 최적화되므로 항상 최고다."

**반론**:
- **선형 앙상블**이 가장 단순하며, **이론적 보장** 있음 (기본 탐지기가 다양하면, 앙상블 분산 ≤ 평균 분산; Breiman, 1996)
- **곱 앙상블**은 **합의** 강제 (두 탐지기 모두 동의해야) → 낮은 거짓 경보, 하지만 이벤트 놓칠 수 있음
- **최대 앙상블**은 **공격적** (어느 탐지기든 트리거) → 높은 재현율, 하지만 거짓 경보 증가 가능
- **학습된 앙상블**은 **레이블된 검증 데이터** 필요 → 검증 세트가 작거나 비대표적이면 과적합 가능

**이론적 모호성**:
- **보정**: 확률의 곱은 독립적이지 않으면 확률이 **아님** → ECE 손상 가능
- **비용**: FN >> FP인 경우 최대 앙상블이 보정이 나빠도 더 낮은 예상 비용 달성 가능

**결론**: 보정 품질(ECE)과 운영 비용 간 트레이드오프 → 단일 승자 없음.

---

### 2.2 예비 증거

#### 2.2.1 현재 하이브리드 탐지기 결과

**현재 구현** (`experiments/hybrid_detector.py`):
```python
# 선형 앙상블: (1 - α) × Rule + α × ML
# 기본 α = 0.5
```

**Smoke 테스트 결과** (seed=42, 단일 파일):
- **SKAB**: Hybrid (α=0.5) AUC-PR = 0.75, Rule = 0.68, ML = 0.70
  - **관찰**: Hybrid > 두 기본 탐지기 (다양성 이득)
- **SMD**: Hybrid AUC-PR = 0.68, Rule = 0.71, ML = 0.62
  - **관찰**: Hybrid < Rule (ML이 약함, 앙상블 끌어내림)

**해석**:
- 선형 앙상블은 두 탐지기가 **비슷한 품질**일 때만 다양성에서 이득
- 한 탐지기가 지배하면, 단순 평균이 **최적이 아닐** 수 있음
- **가설**: 곱 또는 최대 앙상블이 품질 불균형을 더 잘 처리할 수 있음

---

#### 2.2.2 예상 ECE 성능

**보정 가설** (Guo et al. 2017, "On Calibration of Modern Neural Networks" 기반):
- **선형 앙상블**: 기본 모델이 보정되어 있으면 확률 평균이 **보정 유지**
  - ECE(Linear) ≈ (1-α)×ECE(Rule) + α×ECE(ML)
- **곱 앙상블**: 곱셈이 **과신뢰 증폭**
  - 두 탐지기 모두 p=0.9 출력(과신뢰)하면, 곱 = 0.81 (더 나쁨!)
- **최대 앙상블**: 최대값 취하기가 **과신뢰 증폭**
  - max(0.9, 0.8) = 0.9 (여전히 과신뢰)
- **학습된 앙상블**: 확률을 **편향 제거** 학습 가능
  - 하지만 보정된 학습 데이터 필요

**테스트 가능한 예측**: 선형 앙상블이 **최저 ECE**, Max/Product가 **최고 ECE**, 학습된 것은 **중간**.

---

#### 2.2.3 문헌 지원

**참고문헌 1**: Dietterich (2000) - "Ensemble methods in machine learning"
- **발견**: 기본 학습기가 **다양**하고 **무작위보다 나으면** 앙상블이 정확도 향상
- **한계**: 보정이 아닌 정확도에 초점

**참고문헌 2**: Niculescu-Mizil & Caruana (2005) - "Predicting good probabilities with supervised learning"
- **발견**: 기본 모델이 보정되어 있으면 확률 평균(선형 앙상블)이 **잘 보정됨**
- **함의**: Rule과 ML이 사후 보정(Platt/Isotonic)되면 선형 앙상블이 좋은 ECE를 가져야 함

**참고문헌 3** `[TODO: 특히 이상 탐지를 위한 앙상블 방법에 관한 논문 찾기]`

**격차**: 대부분의 앙상블 AD 논문이 **투표**(이진)보다는 **점수 융합**(확률적) 사용. LFactory는 점수 융합 사용 → 경험적 검증 필요.

---

### 2.3 테스트 가능한 가설

**H2.1**: 선형 앙상블이 곱/최대 앙상블 대비 **최저 ECE** (< 0.05) 달성.

**H2.2**: FN 비용 >> FP 비용(비율 ≥ 10)일 때 고불균형 데이터셋(불균형 > 1:50)에서 최대 앙상블이 **최저 예상 비용** 달성.

**H2.3**: 검증 세트 크기 ≥ 500 포인트인 경우 학습된 앙상블(로지스틱 회귀 on [Rule, ML] 특징)이 선형 앙상블 대비 **≥ 5% AUC-PR 개선** 달성.

**H2.4**: 두 기본 탐지기가 **유사한 AUC-PR** (차이 < 0.1)을 가질 때 곱 앙상블이 **최상의 정밀도-재현율 균형** (F1 점수) 달성.

---

### 2.4 수용 기준

**RQ2가 엄격하게 답변되었다고 간주되는 조건**:
- [ ] ≥3개 데이터셋에서 4개 앙상블 방법 모두 구현 및 테스트
- [ ] 다중 메트릭 평가: AUC-PR, ECE, 예상 비용, Point F1, Event F1
- [ ] 통계 테스트: 각 메트릭에 대한 쌍체 t-test 또는 Wilcoxon (n ≥ 5 seeds)
- [ ] 계층 분석: 데이터셋 불균형 수준(low/medium/high)별 결과
- [ ] 파레토 프론티어 플롯: ECE (x축) vs 예상 비용 (y축), 앙상블 방법별 한 점
- [ ] 권장사항: "보정 중요 애플리케이션에는 선형 사용. 비용 중요에는 최대 사용."
- [ ] `experiments/ABLATION_ENSEMBLE_METHODS.md`에 문서화

---

## RQ3: Point vs Event 메트릭

### 전체 질문
**"탐지기에 걸쳐 포인트 단위 F1과 이벤트 단위 F1의 상관관계는 무엇인가?"**

---

### 3.1 왜 비자명한가?

**명백한 (틀린) 답변**: "둘 다 탐지 성능을 측정하므로 높은 상관관계."

**반론**:
- **Point F1**: **모든** 거짓 양성 타임스탬프 페널티 → **정밀** 탐지기 선호 (흩어진 FP 적음)
- **Event F1**: 이벤트의 **임의** 타임스탬프 탐지 여부만 관심 → **재현율 지향** 탐지기 선호 (이벤트 근처 FP OK)

**예시 시나리오**:
```
실제 레이블:    [0,0,0,1,1,1,0,0,0,0]
탐지기 A:      [0,0,0,1,0,0,0,0,0,0]  (보수적, 이벤트 한 번 탐지)
탐지기 B:      [0,0,0,1,1,1,1,1,0,0]  (공격적, 이벤트 + 확장 탐지)

Point F1:
- 탐지기 A: TP=1, FP=0, FN=2 → Precision=1.0, Recall=0.33 → F1=0.50
- 탐지기 B: TP=3, FP=2, FN=0 → Precision=0.60, Recall=1.0 → F1=0.75

Event F1:
- 탐지기 A: 이벤트 탐지 (1/3 포인트) → Event TP=1, FP=0, FN=0 → F1=1.0
- 탐지기 B: 이벤트 탐지 (3/3 포인트) → Event TP=1, FP=1, FN=0 → F1=0.67
                                            (확장 탐지로 인한 FP)

관찰: 탐지기 A가 낮은 Point F1이지만 높은 Event F1 → **음의 상관관계!**
```

**이론적 모호성**: **이상 길이 분포** 및 **탐지기 신뢰도 분포**에 의존.

**결론**: 상관관계는 데이터셋 특화 및 탐지기 특화 → 비자명.

---

### 3.2 예비 증거

#### 3.2.1 기존 결과 (Smoke Test)

**SKAB valve (단일 파일, seed=42)**:
| 탐지기 | Point F1 | Event F1 |
|----------|----------|----------|
| Rule     | 0.68     | 0.72     |
| ML (kNN) | 0.70     | 0.65     |
| Hybrid   | 0.75     | 0.78     |
| SpecCNN  | 0.72     | 0.74     |

**관찰**:
- **Rule**: Event F1 > Point F1 (이벤트 탐지하지만 노이즈 있음)
- **ML**: Event F1 < Point F1 (정밀하지만 일부 이벤트 놓침)
- **상관관계** (대략 추정): Pearson ρ ≈ 0.7 (중간 양의 상관)

**주의사항**: 데이터 포인트 4개만; 전체 배치 평가 필요 (모든 탐지기 × 모든 파일).

---

#### 3.2.2 이론적 예측

**시나리오 1: 긴 이상 이벤트** (지속 시간 > 50 샘플)
- Point F1 ≈ Event F1 (탐지기가 ≥1 포인트 탐지하면, 많은 포인트 탐지)
- **예상 상관관계**: ρ > 0.8 (높음)

**시나리오 2: 짧은 이상 이벤트** (지속 시간 < 10 샘플)
- Point F1 << Event F1 (1/5 포인트 탐지가 이벤트에 충분, 하지만 포인트 재현율 손상)
- **예상 상관관계**: ρ < 0.5 (낮음~중간)

**시나리오 3: 혼합 이상 길이**
- **예상 상관관계**: ρ ≈ 0.6 ± 0.2 (중간)

**SKAB 이상 길이 분포** `[TODO: 2주차까지 분석]`:
- [ ] 이상 이벤트 길이의 중위수, 평균, 표준편차 계산
- [ ] 이벤트 길이별 상관관계 계층화 (짧음/중간/긺)

---

#### 3.2.3 문헌 지원

**참고문헌 1**: Tatbul et al. (2018) - "Precision and Recall for Time Series"
- **발견**: 포인트 단위 메트릭이 긴 이벤트에 대해 **지나치게 엄격** (확장 탐지 페널티)
- **권장사항**: 시계열에 이벤트 기반 메트릭 사용
- **한계**: 경험적 상관관계 분석 없음

**참고문헌 2**: Hundman et al. (2018) - "Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding"
- **발견**: NASA SMAP 데이터셋 - Event F1이 주요 메트릭; 포인트 F1 보고 안 됨
- **함의**: 커뮤니티 합의는 이벤트 메트릭이 더 중요

**참고문헌 3**: Xu et al. (2018) - "Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications"
- **발견**: **둘 다** 포인트 F1 및 "adjusted F1" (이벤트 F1과 유사) 보고
- **관찰**: Point F1 = 0.82, Adjusted F1 = 0.91 → Event F1 > Point F1 (SKAB와 일치)

**격차**: 어떤 논문도 여러 탐지기/데이터셋에 걸쳐 포인트 vs 이벤트 F1의 **산점도** 제공하지 않음.

**LFactory 기여**: 체계적 상관관계 분석.

---

### 3.3 테스트 가능한 가설

**H3.1**: 포인트 F1과 이벤트 F1이 모든 탐지기와 데이터셋에 걸쳐 **중간 양의 상관관계** (0.5 < ρ < 0.8).

**H3.2**: 상관관계가 **긴 이상 이벤트**를 가진 데이터셋(중위수 지속 시간 > 50 샘플)에서 짧은 이벤트(< 10 샘플)보다 **더 높음**.

**H3.3**: **규칙 기반 탐지기** (local thresholding)가 **ML 기반 탐지기** (global modeling)보다 **더 높은 Event F1 / Point F1 비율**.

**H3.4**: **트레이드오프 프론티어** 존재: 고불균형 데이터셋에서 포인트 F1 > 0.9와 이벤트 F1 > 0.9를 동시에 달성하는 탐지기 없음.

---

### 3.4 수용 기준

**RQ3이 엄격하게 답변되었다고 간주되는 조건**:
- [ ] 전체 배치 평가: 모든 탐지기 × 모든 파일 (상관관계를 위한 ≥ 50 데이터 포인트)
- [ ] 산점도: Point F1 (x) vs Event F1 (y), 탐지기 유형별 색상 코딩
- [ ] 통계 분석:
  - 95% CI를 갖는 Pearson 상관 계수
  - Spearman 순위 상관 (비선형인 경우)
  - 강건한 CI를 위한 Bootstrap 리샘플링 (n=1000)
- [ ] 계층 분석: 데이터셋별, 이상 길이 빈별 상관관계
- [ ] 도메인 권장사항: "제조에서는 이벤트 F1 우선순위 (상관관계 약함; 포인트 F1 최적화가 이벤트 F1 손상 가능)"
- [ ] `docs/METRICS_TRADEOFF.md`에 문서화

---

## RQ4: 비용 민감성

### 전체 질문
**"FN/FP 비용 비율이 데이터셋 불균형 및 SNR과 어떻게 달라져야 하는가?"**

---

### 4.1 왜 비자명한가?

**명백한 (틀린) 답변**: "더 높은 불균형 → 더 높은 FN 비용 (항상)."

**반론**:
- **고불균형 + 낮은 SNR**: 이상이 **탐지 어려우면** (낮은 SNR), FN 비용 증가가 단지 임계값 증가 → 더욱 낮은 재현율 → **더 높은 총 비용**
- **저불균형 + 높은 FN 비용**: 임계값 → 0으로 이어질 수 있음 (모든 것을 이상으로 분류) → 거짓 경보로부터 생산 중단

**이론적 모호성**:
- 비용 비율이 **기본 탐지기 품질** (보정 곡선)과 상호작용
- 최적 비율이 **운영 제약** (예: 최대 허용 가능 거짓 경보율)에 의존

**결론**: 최적 비용 비율은 (불균형, SNR, 탐지기 품질)의 함수 → 비자명한 최적화 문제.

---

### 4.2 예비 증거

#### 4.2.1 현재 비용 구성

**기본 비용 행렬** (`experiments/cost_threshold.py`):
```python
costs = (0.0, 1.0, 5.0, 0.0)  # C_TN, C_FP, C_FN, C_TP
# FN 비용 = 5 × FP 비용
```

**Smoke 테스트 결과** (SKAB, seed=42):
- **비용 비율 = 5**: 최적 임계값 τ* = 0.35 → 예상 비용 = 120
- **비용 비율 = 1**: 최적 임계값 τ* = 0.50 → 예상 비용 = 200
- **비용 비율 = 10**: 최적 임계값 τ* = 0.20 → 예상 비용 = 95

**관찰**: 비용 비율 증가하면, 임계값 감소 (더 공격적) → 탐지기가 잘 보정되어 있으면 더 낮은 예상 비용.

**질문**: 탐지기가 보정 불량이면? 비용 비율이 여전히 도움이 되는가?

---

#### 4.2.2 불균형 vs 최적 비용 비율 (가설)

**이론적 프레임워크** (Elkan, 2001 - "The Foundations of Cost-Sensitive Learning"):
- 최적 임계값: `τ* = p(anomaly) × (C_FP / (C_FP + C_FN))`
- 불균형 = 1:100 (p(anomaly) = 0.01)이고, τ* = 0.5를 원하면:
  - 해결: `0.5 = 0.01 × (C_FP / (C_FP + C_FN))`
  - 단순화: `C_FP / (C_FP + C_FN) = 50` → **불가능** (비율이 > 1일 수 없음)
- **함의**: 극단 불균형의 경우, 비용 비율만으로는 균형 임계값 달성 불가

**개선된 가설**:
- **중간 불균형** (1:10 ~ 1:50): 비용 비율이 보상 가능 → 선형 관계
- **극단 불균형** (> 1:100): 비용 비율 포화 → 리샘플링 또는 이상-사전분포 조정 필요

**테스트 가능**: (불균형, 비용 비율)에 대한 그리드 탐색 → 스윗 스팟 찾기.

---

#### 4.2.3 SNR vs 비용 민감성

**가설**: 낮은 SNR 데이터셋은 임계값 붕괴를 피하기 위해 **보수적** 비용 비율 (낮은 FN 페널티) 필요.

**메커니즘**:
- 낮은 SNR → 탐지기 점수가 노이즈 많음 → 넓은 신뢰 구간
- 높은 FN 비용 → 임계값이 매우 낮게 밀림 → 많은 FP
- **총 비용**: FPs × C_FP + FNs × C_FN
  - 임계값 → 0이면: FPs → ∞, FNs → 0 → 총 비용 폭발

**예상 발견**: 최적 비용 비율이 SNR 감소에 따라 **감소**.

**측정** `[TODO: 2주차까지 SKAB/SMD의 SNR 계산]`:
- [ ] SNR 추정: `10 × log10(signal_power / noise_power)`
  - 신호 파워: 이상 세그먼트의 분산
  - 노이즈 파워: 정상 세그먼트의 분산 (추세 제거 후 잔차)
- [ ] 플롯: SNR (x축) vs 최적 비용 비율 (y축)

---

#### 4.2.4 문헌 지원

**참고문헌 1**: Elkan (2001) - "The Foundations of Cost-Sensitive Learning"
- **발견**: 최적 임계값이 클래스 사전분포와 비용 행렬에 의존
- **공식**: `τ* = p(neg) × (C_FP / (C_FP + C_FN))`
- **한계**: **완벽한 보정** 및 **정적 비용** 가정

**참고문헌 2**: Ling et al. (2006) - "Cost-Sensitive Learning and the Class Imbalance Problem"
- **발견**: 불균형 > 1:100의 경우, 비용 민감 임계값 설정만으로 **불충분**; 리샘플링 필요
- **함의**: LFactory는 극단 불균형에 SMOTE 또는 언더샘플링 구현 필요할 수 있음

**참고문헌 3**: Zhou & Liu (2006) - "Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem"
- **발견**: 비용 비율이 `sqrt(imbalance)`로 척도 조정되어야 함 (경험적)
- **예**: 불균형 = 1:100 → 비용 비율 ≈ 10
- **테스트 가능**: `cost_ratio = a × imbalance^b` 적합하고 b ≈ 0.5 찾기

**참고문헌 4** `[TODO: 제조 특화 비용 분석 찾기]`

---

### 4.3 테스트 가능한 가설

**H4.1**: 최적 FN/FP 비용 비율이 중간 불균형(1:10 ~ 1:50)에 대해 데이터셋 불균형과 **선형 증가**.
- **공식**: `cost_ratio ≈ 0.5 × imbalance` (예: 불균형=20 → 비율=10)

**H4.2**: 극단 불균형(> 1:100)의 경우, 최적 비용 비율이 ≈ 20에서 **포화**되고, 비율 추가 증가가 예상 비용 **증가** (임계값 붕괴).

**H4.3**: 최적 비용 비율이 SNR 감소에 따라 **감소**:
- 높은 SNR (> 10 dB): 비율 최대 20이 효과적
- 낮은 SNR (< 3 dB): 비율 ≤ 5이어야 함

**H4.4**: 비용 민감성이 **탐지기 품질**과 상호작용:
- 잘 보정된 탐지기 (ECE < 0.05): 비용 비율이 직접 임계값으로 변환
- 보정 불량 탐지기 (ECE > 0.15): 비용 비율이 예상 비용에 **약한 효과**

---

### 4.4 수용 기준

**RQ4가 엄격하게 답변되었다고 간주되는 조건**:
- [ ] 그리드 탐색: 불균형 ∈ {0.01, 0.02, 0.05, 0.10}, 비용 비율 ∈ {1, 3, 5, 10, 20}
- [ ] 다양한 불균형을 가진 ≥3개 데이터셋 (SKAB ≈ 0.05, SMD ≈ 0.03, 제어 가능한 Synthetic)
- [ ] 각 데이터셋에 대한 SNR 계산; 최적 비용 비율과의 상관관계 분석
- [ ] 히트맵: 불균형 (x) × 비용 비율 (y) → 색상 = 예상 비용
- [ ] 적합 모델: `cost_ratio = f(imbalance, SNR)` with R² > 0.7
- [ ] 실무자 가이드 테이블:
  ```
  | 불균형 | SNR    | 권장 비용 비율 |
  |-----------|--------|------------------------|
  | 1:10      | > 5 dB | 5                      |
  | 1:50      | > 5 dB | 10                     |
  | 1:100     | > 5 dB | 15 (리샘플링 포함)   |
  | Any       | < 3 dB | 3 (보수적)       |
  ```
- [ ] `experiments/COST_SENSITIVITY_ANALYSIS.md`에 문서화

---

## 요약: RQ 답변을 위한 로드맵

### 2주차 작업 (데이터 분석 기초)
- [ ] **RQ1 준비**: SKAB 및 AIHub의 주파수 분석 (PSD, 식별력 있는 밴드)
- [ ] **RQ3 준비**: 이상 이벤트 길이 분포 계산
- [ ] **RQ4 준비**: 모든 데이터셋에 대한 SNR 추정

### 3주차 작업 (탐지기 개선)
- [ ] **RQ1**: 시간 인식 ML 탐지기 구현, 절제 실행
- [ ] **RQ2**: 곱/최대/학습된 앙상블 변형 구현

### 4주차 작업 (전체 평가)
- [ ] **RQ1**: 전체 배치 평가 (모든 탐지기 × 모든 파일)
- [ ] **RQ2**: 통계 테스트를 통한 앙상블 방법 비교
- [ ] **RQ3**: 산점도 분석 (Point F1 vs Event F1)
- [ ] **RQ4**: 비용 비율 × 불균형에 대한 그리드 탐색

### 5주차 작업 (분석 및 문서화)
- [ ] 모든 RQ에 대한 통계적 유의성 테스트
- [ ] 절제/분석 마크다운 파일 생성
- [ ] RQ 답변으로 EXPERIMENT_REPORT.md 업데이트
- [ ] 각 RQ에 대한 실무자 가이드라인

---

## 현재 상태에 대한 정직한 평가

### 우리가 아는 것
- ✅ 하이브리드 탐지기가 Rule 기준보다 개선 (예비 증거)
- ✅ 보정이 ECE 감소 (예상되었지만 SKAB에서 검증됨)
- ✅ 비용 민감 임계값 설정이 최적 임계값 변경 (검증됨)

### 우리가 모르는 것 (RQ 조사 필요)
- ❓ **RQ1**: 주파수 특징이 실제로 더 나은지 (현재 SpecCNN 밴드는 임의적)
- ❓ **RQ2**: 어떤 앙상블 방법이 최고인지 (지금까지 선형만 테스트)
- ❓ **RQ3**: 포인트 vs 이벤트 상관관계 (데이터 포인트 4개만, 불충분)
- ❓ **RQ4**: 비용 비율 설정 방법 (현재 기본값 5는 임의적)

### 우리가 의심하지만 주장할 수 없는 것
- 🤔 SpecCNN이 SKAB(주기적 기계)에서 뛰어나야 함 → 주파수 분석 증명 필요
- 🤔 곱 앙상블이 고불균형에 더 나을 수 있음 → 비교 필요
- 🤔 포인트와 이벤트 F1이 약하게 상관 → 전체 배치 데이터 필요
- 🤔 비용 비율이 불균형으로 척도 조정되어야 함 → 그리드 탐색 필요

**다음 단계**: "의심"에서 "알음"으로 이동하기 위해 2주차 데이터 분석 작업 실행.

---

## 참고문헌

1. Breiman, L. (1996). Bagging predictors. *Machine learning*, 24(2), 123-140.
2. Chakraborty, D., et al. (2020). Deep learning for time-series anomaly detection: A survey. *Preprint*.
3. Dietterich, T. G. (2000). Ensemble methods in machine learning. *MCS*.
4. Elkan, C. (2001). The foundations of cost-sensitive learning. *IJCAI*.
5. Guo, C., et al. (2017). On calibration of modern neural networks. *ICML*.
6. Hundman, K., et al. (2018). Detecting spacecraft anomalies using LSTMs. *KDD*.
7. Katser, I. D., & Kozitsin, V. (2020). Skoltech Anomaly Benchmark (SKAB). *arXiv*.
8. Ling, C. X., et al. (2006). Cost-sensitive learning and the class imbalance problem. *Encyclopedia of ML*.
9. Malhotra, P., et al. (2016). LSTM-based encoder-decoder for multi-sensor anomaly detection. *ICML Workshop*.
10. Niculescu-Mizil, A., & Caruana, R. (2005). Predicting good probabilities with supervised learning. *ICML*.
11. Tatbul, N., et al. (2018). Precision and recall for time series. *NeurIPS*.
12. Xu, H., et al. (2018). Unsupervised anomaly detection via VAE for seasonal KPIs. *WWW*.
13. Zhou, Z. H., & Liu, X. Y. (2006). Training cost-sensitive neural networks. *ICML*.

---

**버전 히스토리**:
- 1.0 (2025-10-01): 예비 증거 및 가설을 포함한 초안
- 1.1 (2주차 계획): SKAB 주파수 분석, SNR 추정으로 업데이트
- 2.0 (5주차 계획): 모든 RQ에 대한 실험 결과로 완성
